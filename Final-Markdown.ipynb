{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "behind-merit",
   "metadata": {},
   "source": [
    "# Classification Assesment Technical Report\n",
    "\n",
    "\n",
    "### Before running code you must :\n",
    "\n",
    " * Make sure to have all data being used in the appropriate path(data/..)\n",
    " * Using the correct python version (>3) \n",
    " * Make sure to have all the libraries being used installed on your machine.\n",
    "\n",
    "### Workflow being implemented for the assesment :\n",
    "        \n",
    "  1. Import data in the enviroment\n",
    "  2. Exploration analysis and summary statistics\n",
    "  3. Feature Importance analysis (using a decision tree)\n",
    "  4. Fitting multiple models to assess begininng state\n",
    "  5. Tune models hyperparameters to try investigsate complexity trade-off.\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  5. Feature importance on the best perfoming model and reduce complexity (overfit)\n",
    "  6. Tuning hyperparameters of best performing model\n",
    "  7. Results of the best perfoming model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-honduras",
   "metadata": {},
   "source": [
    "###### [1] Importing the dataset in python enviroment\n",
    "\n",
    "We are also importing all the appropriate libraries that will be used in the following process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "international-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important libraries for data frame manipulations.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys as sys\n",
    "\n",
    "# For fitting logistic regression.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# For fitting a random forest.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For fitting a decision tree.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# For fitting a bagging classifier.\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Importing accuracy_score to auto calculate our classifiers accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Finding static metrics\n",
    "import statistics\n",
    "\n",
    "# To apply a gridsearch in hyperparameters for random forest.\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affiliated-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the training and testing set already provided.\n",
    "training_data = pd.read_csv(\"data/train.csv\")\n",
    "testing_data = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-advice",
   "metadata": {},
   "source": [
    "###### [2] Exploration Analysis applied on the data\n",
    "\n",
    "This step is fundamental for the construction of our candidate classifiers. We have to make sure that our two datasets have the same strucuture (covariates). However this step is undertaken with extreme caution, because the test data should not be viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stretch-mounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Data columns (total 32 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   id      300000 non-null  int64  \n",
      " 1   cat0    300000 non-null  object \n",
      " 2   cat1    300000 non-null  object \n",
      " 3   cat2    300000 non-null  object \n",
      " 4   cat3    300000 non-null  object \n",
      " 5   cat4    300000 non-null  object \n",
      " 6   cat5    300000 non-null  object \n",
      " 7   cat6    300000 non-null  object \n",
      " 8   cat7    300000 non-null  object \n",
      " 9   cat8    300000 non-null  object \n",
      " 10  cat9    300000 non-null  object \n",
      " 11  cat10   300000 non-null  object \n",
      " 12  cat11   300000 non-null  object \n",
      " 13  cat12   300000 non-null  object \n",
      " 14  cat13   300000 non-null  object \n",
      " 15  cat14   300000 non-null  object \n",
      " 16  cat15   300000 non-null  object \n",
      " 17  cat16   300000 non-null  object \n",
      " 18  cat17   300000 non-null  object \n",
      " 19  cat18   300000 non-null  object \n",
      " 20  cont0   300000 non-null  float64\n",
      " 21  cont1   300000 non-null  float64\n",
      " 22  cont2   300000 non-null  float64\n",
      " 23  cont3   300000 non-null  float64\n",
      " 24  cont4   300000 non-null  float64\n",
      " 25  cont5   300000 non-null  float64\n",
      " 26  cont6   300000 non-null  float64\n",
      " 27  cont7   300000 non-null  float64\n",
      " 28  cont8   300000 non-null  float64\n",
      " 29  cont9   300000 non-null  float64\n",
      " 30  cont10  300000 non-null  float64\n",
      " 31  target  300000 non-null  int64  \n",
      "dtypes: float64(11), int64(2), object(19)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Having info analysis on the training dataset.\n",
    "training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "contained-literature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   id      200000 non-null  int64  \n",
      " 1   cat0    200000 non-null  object \n",
      " 2   cat1    200000 non-null  object \n",
      " 3   cat2    200000 non-null  object \n",
      " 4   cat3    200000 non-null  object \n",
      " 5   cat4    200000 non-null  object \n",
      " 6   cat5    200000 non-null  object \n",
      " 7   cat6    200000 non-null  object \n",
      " 8   cat7    200000 non-null  object \n",
      " 9   cat8    200000 non-null  object \n",
      " 10  cat9    200000 non-null  object \n",
      " 11  cat10   200000 non-null  object \n",
      " 12  cat11   200000 non-null  object \n",
      " 13  cat12   200000 non-null  object \n",
      " 14  cat13   200000 non-null  object \n",
      " 15  cat14   200000 non-null  object \n",
      " 16  cat15   200000 non-null  object \n",
      " 17  cat16   200000 non-null  object \n",
      " 18  cat17   200000 non-null  object \n",
      " 19  cat18   200000 non-null  object \n",
      " 20  cont0   200000 non-null  float64\n",
      " 21  cont1   200000 non-null  float64\n",
      " 22  cont2   200000 non-null  float64\n",
      " 23  cont3   200000 non-null  float64\n",
      " 24  cont4   200000 non-null  float64\n",
      " 25  cont5   200000 non-null  float64\n",
      " 26  cont6   200000 non-null  float64\n",
      " 27  cont7   200000 non-null  float64\n",
      " 28  cont8   200000 non-null  float64\n",
      " 29  cont9   200000 non-null  float64\n",
      " 30  cont10  200000 non-null  float64\n",
      "dtypes: float64(11), int64(1), object(19)\n",
      "memory usage: 47.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Having info analysis on the testing dataset\n",
    "testing_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-force",
   "metadata": {},
   "source": [
    "From the above results, we confirm that the two datasets do not hold any null values and they are of the same design structure.\n",
    "\n",
    " * Both datasets contain 19 factor type covariates\n",
    " * Both datasets contain 11 float type covariates\n",
    " * The training dataset has 1 extra column of type int which is our response variable of training\n",
    " * Training set is constructed by 300K rows\n",
    " * Testing set is constructed by 200K rows\n",
    " \n",
    "We now check the different levels of each factor variable. The reason behind this action is because in Python our testing and training set must have the same number of factor levels for the identical covariate. When we apply 1-hot-encoder, each level will act as a unique covariate. With this being said if one factor covariate has different number levels between the two sets, the design structure wont be appropriate.\n",
    "\n",
    "**1-Hot-Encoder** is a method used in Python to overcome the different levels of the categorical (string) columns of the data. Because Python models only understand numerical values, we need to convert the string data to numerical without implementing a mathematical meaning to them. This technique creates a new column for **each** different level and filles in the cells with **binary values** (1 = true, 0 = false). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "patent-reducing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>cat11</th>\n",
       "      <th>cat12</th>\n",
       "      <th>cat13</th>\n",
       "      <th>cat14</th>\n",
       "      <th>cat15</th>\n",
       "      <th>cat16</th>\n",
       "      <th>cat17</th>\n",
       "      <th>cat18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>51</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>299</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>AH</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>DJ</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>223525</td>\n",
       "      <td>90809</td>\n",
       "      <td>168694</td>\n",
       "      <td>187251</td>\n",
       "      <td>129385</td>\n",
       "      <td>238563</td>\n",
       "      <td>187896</td>\n",
       "      <td>45818</td>\n",
       "      <td>42380</td>\n",
       "      <td>201945</td>\n",
       "      <td>31584</td>\n",
       "      <td>258932</td>\n",
       "      <td>257139</td>\n",
       "      <td>292712</td>\n",
       "      <td>160166</td>\n",
       "      <td>203574</td>\n",
       "      <td>206906</td>\n",
       "      <td>247125</td>\n",
       "      <td>255482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cat0    cat1    cat2    cat3    cat4    cat5    cat6    cat7  \\\n",
       "count   300000  300000  300000  300000  300000  300000  300000  300000   \n",
       "unique       2      15      19      13      20      84      16      51   \n",
       "top          A       I       A       A       E      BI       A      AH   \n",
       "freq    223525   90809  168694  187251  129385  238563  187896   45818   \n",
       "\n",
       "          cat8    cat9   cat10   cat11   cat12   cat13   cat14   cat15  \\\n",
       "count   300000  300000  300000  300000  300000  300000  300000  300000   \n",
       "unique      61      19     299       2       2       2       2       4   \n",
       "top         BM       A      DJ       A       A       A       A       B   \n",
       "freq     42380  201945   31584  258932  257139  292712  160166  203574   \n",
       "\n",
       "         cat16   cat17   cat18  \n",
       "count   300000  300000  300000  \n",
       "unique       4       4       4  \n",
       "top          D       D       B  \n",
       "freq    206906  247125  255482  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using describe function to check the levels of the categories in training dataset.\n",
    "training_data.describe(include=[object])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "turned-professor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>cat11</th>\n",
       "      <th>cat12</th>\n",
       "      <th>cat13</th>\n",
       "      <th>cat14</th>\n",
       "      <th>cat15</th>\n",
       "      <th>cat16</th>\n",
       "      <th>cat17</th>\n",
       "      <th>cat18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>51</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>295</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>AH</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>DJ</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>149023</td>\n",
       "      <td>60152</td>\n",
       "      <td>112465</td>\n",
       "      <td>124506</td>\n",
       "      <td>86073</td>\n",
       "      <td>158916</td>\n",
       "      <td>125098</td>\n",
       "      <td>30593</td>\n",
       "      <td>28368</td>\n",
       "      <td>134223</td>\n",
       "      <td>21166</td>\n",
       "      <td>172586</td>\n",
       "      <td>171098</td>\n",
       "      <td>195016</td>\n",
       "      <td>106607</td>\n",
       "      <td>135542</td>\n",
       "      <td>137908</td>\n",
       "      <td>165066</td>\n",
       "      <td>170068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cat0    cat1    cat2    cat3    cat4    cat5    cat6    cat7  \\\n",
       "count   200000  200000  200000  200000  200000  200000  200000  200000   \n",
       "unique       2      15      19      13      20      84      16      51   \n",
       "top          A       I       A       A       E      BI       A      AH   \n",
       "freq    149023   60152  112465  124506   86073  158916  125098   30593   \n",
       "\n",
       "          cat8    cat9   cat10   cat11   cat12   cat13   cat14   cat15  \\\n",
       "count   200000  200000  200000  200000  200000  200000  200000  200000   \n",
       "unique      61      19     295       2       2       2       2       4   \n",
       "top         BM       A      DJ       A       A       A       A       B   \n",
       "freq     28368  134223   21166  172586  171098  195016  106607  135542   \n",
       "\n",
       "         cat16   cat17   cat18  \n",
       "count   200000  200000  200000  \n",
       "unique       4       4       4  \n",
       "top          D       D       B  \n",
       "freq    137908  165066  170068  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using describe function to check the levels of categories in testing dataset.\n",
    "testing_data.describe(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-investigation",
   "metadata": {},
   "source": [
    "From the above results we can view that in the testing data column 'cat10' has 4 extra unique values. For this reason we will need to 1-hot-encode the categorical data for both datasets together and split them again to the beginning states.\n",
    "\n",
    "Before we merge the two datasets and ecnode them, we need to isolate the response in the training dataset alone. Additionally we need to remove the index column from the data, because it should not be used in the training or predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hispanic-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a copy of data frames to 1-hot-encode\n",
    "\n",
    "## TRAINING DATA\n",
    "train_encoder = training_data.copy()\n",
    "# Need to drop response varibale from training and hold it seperate.\n",
    "trainY_response = training_data['target'].copy()\n",
    "train_encoder.drop('target', axis = 1, inplace = True)\n",
    "# We also need to remove the index variables because they should not be considered in the model training\n",
    "train_encoder.drop('id', axis = 1, inplace = True)\n",
    "\n",
    "## TESTING DATA\n",
    "test_encoder = testing_data.copy()\n",
    "test_encoder.drop('id', axis = 1, inplace = True)\n",
    "\n",
    "## MERGED DATA\n",
    "# This will concatenate the test data rows below the train data\n",
    "# The first 300K rows will be the train.\n",
    "# The last 200K rows will be the testing.\n",
    "merged_encoder = pd.concat([train_encoder, test_encoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "breathing-guard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    }
   ],
   "source": [
    "# Using get_dummies() which is the same thing as 1-hot-encoder but ignores numerical values.\n",
    "%time\n",
    "merged_encoder = pd.get_dummies(merged_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rising-constraint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 500000 entries, 0 to 199999\n",
      "Columns: 642 entries, cont0 to cat18_D\n",
      "dtypes: float64(11), uint8(631)\n",
      "memory usage: 346.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Checking if the one hot encoder worked.\n",
    "merged_encoder.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-cartridge",
   "metadata": {},
   "source": [
    "From the above result we can understand that our data has become a large sparse matrix of values. This is one of the consequences when using a 1-Hot-Encoder technique. We now need to split the data again back to training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "swedish-hammer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 300000 entries, 0 to 299999\n",
      "Columns: 642 entries, cont0 to cat18_D\n",
      "dtypes: float64(11), uint8(631)\n",
      "memory usage: 208.0 MB\n"
     ]
    }
   ],
   "source": [
    "# First 300K rows is our training set.\n",
    "trainingX_data = merged_encoder.iloc[:300000,:].copy()\n",
    "trainingX_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "appointed-electric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200000 entries, 0 to 199999\n",
      "Columns: 642 entries, cont0 to cat18_D\n",
      "dtypes: float64(11), uint8(631)\n",
      "memory usage: 138.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Last 200K rows is our testing set.\n",
    "testingX_data = merged_encoder.iloc[300000:,:].copy()\n",
    "testingX_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-terminology",
   "metadata": {},
   "source": [
    "We can now explore correlation relations between the covariates with response. This will help us identify the covariates that mostly influence the response value. The covariates that mostly influence the response values are also most probably the most important covariates to consider in our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "portuguese-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the trainingX_data with trainY_data to see the correlations\n",
    "training_all = pd.concat([trainingX_data.copy(), trainY_response.copy()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "outer-september",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 24.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Computing correlation relations. (takes about 5-6 minutes btw. Time below is wrong)\n",
    "training_corr_influnce = training_all.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "embedded-amber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target     1.000000\n",
       "cat16_B    0.522759\n",
       "cat15_D    0.467675\n",
       "cat14_B    0.302301\n",
       "cat18_D    0.299653\n",
       "cat11_B    0.285503\n",
       "cat0_A     0.268109\n",
       "cat18_C    0.260021\n",
       "cat17_C    0.237540\n",
       "cont5      0.215184\n",
       "cat2_Q     0.213173\n",
       "cat13_B    0.205714\n",
       "cat8_K     0.194427\n",
       "cat1_L     0.190920\n",
       "cont6      0.189832\n",
       "cont8      0.183726\n",
       "cont1      0.164655\n",
       "cat7_AF    0.160744\n",
       "cat9_A     0.156035\n",
       "cat4_H     0.153590\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the correlation with response in sorted way (20 most positive influential features).\n",
    "training_corr_influnce[\"target\"].sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wicked-singing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat16_D    -0.505020\n",
       "cat15_B    -0.435327\n",
       "cat18_B    -0.409153\n",
       "cat14_A    -0.302301\n",
       "cat11_A    -0.285503\n",
       "cat0_B     -0.268109\n",
       "cat17_D    -0.267343\n",
       "cat13_A    -0.205714\n",
       "cat1_I     -0.198141\n",
       "cat4_E     -0.165314\n",
       "cat6_A     -0.149729\n",
       "cont3      -0.148316\n",
       "cat2_A     -0.141533\n",
       "cat9_E     -0.126067\n",
       "cat10_CR   -0.100503\n",
       "cat1_A     -0.095467\n",
       "cat2_C     -0.093678\n",
       "cat12_B    -0.083143\n",
       "cont4      -0.075585\n",
       "cat7_E     -0.075031\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the correlation with response in sorted way (20 most negative influential).\n",
    "training_corr_influnce[\"target\"].sort_values(ascending=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-interview",
   "metadata": {},
   "source": [
    "From the above results we can see some values close to 0, which indicates they dont influence the response variable. We will further investigate feature importance analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-spokesman",
   "metadata": {},
   "source": [
    "**One-Hot-Encoder** is completed now and **Correlation analysis of response** has also been applied as an indication of what features will be valuable in our training.\n",
    "A quick recap to our different data.frames we have to now.\n",
    "   \n",
    " 1. NON-One-Hot-Encoded-Data\n",
    " * training_data = Full training dataset to reference back to it if mistake occurs further on.\n",
    " * testing_data = Full testing dataset to reference back to it if mistake occures.\n",
    " 2. One-Hot-Encoded-Data\n",
    " * merged_encoder = Both datasets merged and encoded\n",
    " * trainingX_data = Training dataset explanatory variables. (values we will use for training)\n",
    " * trainY_response = Training dataset response variable. (value used to training models in construnction)\n",
    " * testingX_data = Testing dataser explanatory variables (values we will use for predictions.)\n",
    " 3. Extra infomration\n",
    " * training_corr_influnce = Holds correlation values between variables\n",
    " * training_all = Holds the 1-Hot-Encoded explanatory variables with the response, to calculate correlations.\n",
    " \n",
    "More exploration analysis and graph analysis can be found in the external file EDA.ipynp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-unemployment",
   "metadata": {},
   "source": [
    "###### [3] Feature Importance analysis (using a decision tree)\n",
    "\n",
    "From the data wrangling and convertions applied above, we have resulted to very sparsed matrix for the training set that consists of 300K rows and 642 columns. This can cause issues in terms of time/computational complexity and can be an issue in the overfit/underfit trade-off of our analysis. For this reason, we have chosen to apply feature important analysis and keep the analysis process only with features that constribute to our response.\n",
    "\n",
    "Feature importance code and idea was motivated/inspired by a [youtube](https://www.youtube.com/watch?v=NPdn3YPkg9w) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adjustable-secondary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.3 s, sys: 1.58 s, total: 34.9 s\n",
      "Wall time: 36.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=5059)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fitting a random forest with only 5 trees to get feature importance.\n",
    "DT_feature_importance = DecisionTreeClassifier(criterion='entropy', random_state=5059)\n",
    "DT_feature_importance.fit(trainingX_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "saved-buffalo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features that have an impact on Y variables is (434,)\n"
     ]
    }
   ],
   "source": [
    "# Finding the features that are important.\n",
    "features = []\n",
    "feature_score = []\n",
    "# Appenind all scores in arrays to create a data frame.\n",
    "for i, column in enumerate(trainingX_data):\n",
    "    features.append(column)\n",
    "    feature_score.append(DT_feature_importance.feature_importances_[i])\n",
    "    \n",
    "# Create a dataframe with these arrays.\n",
    "feature_score_df = zip(features, feature_score)\n",
    "feature_score_df = pd.DataFrame(feature_score_df, columns = ['Feature', 'Feature Score'])\n",
    "\n",
    "# Sort the data frame according to feature score.\n",
    "feature_score_df = feature_score_df.sort_values('Feature Score', ascending=False).reset_index()\n",
    "# Removing all features that 0 influence on the response.\n",
    "feature_keeping = feature_score_df[feature_score_df['Feature Score'] > 0.0]\n",
    "# Keeping the columns that we constribute to the result.\n",
    "feature_keeping = feature_keeping['Feature'].copy()\n",
    "print(\"Number of features that have an impact on Y variables is {}\".format(feature_keeping.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-today",
   "metadata": {},
   "source": [
    "From the above computations we can observe that over 200 features did not constribute at all in the decision tree classification in predicting the Y variable. For this reason we will use the above result to reduce the dimensions of the training set that will be used to construct the model.\n",
    "\n",
    "**NOTE** :\n",
    "Because we are changing the structure of the training data dimensions, we have to change it for the testing data dimensions as well. Our two datasets should follow the the structure so predictions can be obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "transsexual-messaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial structure of the data was (300000, 642)\n",
      "The new dimensions of our training data is (300000, 434)\n",
      "The new dimensions of our testing data is (200000, 434)\n"
     ]
    }
   ],
   "source": [
    "# Showing the initial dimension state.\n",
    "print(\"The initial structure of the data was {}\".format(trainingX_data.shape))\n",
    "# Reducing the dimensions of the data.\n",
    "trainingX_data = trainingX_data[feature_keeping]\n",
    "testingX_data = testingX_data[feature_keeping]\n",
    "\n",
    "# Showing the new dimension state of our data.\n",
    "print(\"The new dimensions of our training data is {}\".format(trainingX_data.shape))\n",
    "print(\"The new dimensions of our testing data is {}\".format(testingX_data.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-copper",
   "metadata": {},
   "source": [
    "######  [4] Fitting models to assess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-temperature",
   "metadata": {},
   "source": [
    "We first create a function that enables us to convert hte predicted array to correct format, so we can obtain perfomance metric (Accuracy) results from kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "impressive-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function\n",
    "# It writes a CSV file in the correct format so we can obtain perfomance metrics from kaggle/\n",
    "# INPUT ARGUMENT:\n",
    "# preditions: the array that holds the predictions\n",
    "# id_row: an array the hold the id index column of the testing data\n",
    "# model: string with file being saved with.\n",
    "# OUTPUT:\n",
    "# no variable output, it writes a CSV on local machine.\n",
    "def convert_prediction_format(predictions, id_row, model):\n",
    "    file_submit = pd.concat([id_row, predictions], axis=1)\n",
    "    file_submit.to_csv(model, index = False, header=['id', 'target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-insert",
   "metadata": {},
   "source": [
    "*Logistic Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "reflected-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a logistic regression.\n",
    "log_reg = LogisticRegression(solver=\"saga\", max_iter= 1000, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fixed-customer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 47s, sys: 2.47 s, total: 5min 49s\n",
      "Wall time: 5min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=123, solver='saga')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fitting the logistic regression\n",
    "log_reg.fit(trainingX_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "solar-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "y_predicted = pd.DataFrame(log_reg.predict(testingX_data))\n",
    "# Calling function to write the csv file\n",
    "convert_prediction_format(y_predicted, testing_data[['id']], 'logistic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-penalty",
   "metadata": {},
   "source": [
    "These initial predictions had 76.09% accuracy scores. The low accuracy score could be a phenomeno of overfitting, this will have to be further examined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ultimate-combining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using the training data for prediction is  0.8447133333333333\n"
     ]
    }
   ],
   "source": [
    "# We will see how it performs with training data\n",
    "train_predicted = log_reg.predict(trainingX_data)\n",
    "# Calculating the accuracy\n",
    "print(\"Accuracy score using the training data for prediction is \", \n",
    "      accuracy_score(trainY_response, train_predicted, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-leeds",
   "metadata": {},
   "source": [
    "From the above results this could be overfitting since the training data is being predicted with 8% more accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-classics",
   "metadata": {},
   "source": [
    "*Random Forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "shaped-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with 200 decision trees (wanted more, but computationally expensive in our case).\n",
    "# oob_score needs to be true to consider out of bag sampling.\n",
    "Random_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "oriental-romantic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 7s, sys: 9.69 s, total: 3min 16s\n",
      "Wall time: 3min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "Random_forest_model.fit(trainingX_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "medical-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "y_predicted = pd.DataFrame(Random_forest_model.predict(testingX_data))\n",
    "# Calling function to write the csv file\n",
    "convert_prediction_format(y_predicted, testing_data[['id']], 'random-forest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-grain",
   "metadata": {},
   "source": [
    "These initial predictions had 76.11% accuracy scores. Will try and predict with the training data to see if we have a case of overfit here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "qualified-kitty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using the training data for prediction is  0.8459033333333333\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy for training with considering the OOB sample\n",
    "print(\"Accuracy score using the training data for prediction is \", \n",
    "      Random_forest_model.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-rental",
   "metadata": {},
   "source": [
    "The accuracy score here using the testing data indicate we might be overfitting seeing the training data performs 8% better in terms of accuracy.\n",
    "We now use a gridsearch or some values for the hyperparameters to try and optimize our random forest. More complex models does not mean better models. For this reason we test different values for the hyperparameters since we might be overfitting.\n",
    "\n",
    "**NOTE** \n",
    "Because of technology being available to us, it is too expensive to apply a full on grid-search, for this reason we apply random values for the hyperparameters to search in hope of improving accuracy perfomance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "demographic-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example hyperparameters to test.\n",
    "parameter_examine = {\n",
    "    'oob_score': [True],\n",
    "    'max_depth': [5, 10],\n",
    "    'max_features' : ['auto', 'sqrt'],\n",
    "    'n_estimators': [100]\n",
    "}\n",
    "# Create a based model\n",
    "base_forest = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = base_forest,\n",
    "                           param_grid = parameter_examine, \n",
    "                           cv = 3,\n",
    "                           n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "transparent-price",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "CPU times: user 15min, sys: 12.1 s, total: 15min 13s\n",
      "Wall time: 39min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [5, 10], 'max_features': ['auto', 'sqrt'],\n",
       "                         'n_estimators': [100], 'oob_score': [True]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the grid search model to see the best params.\n",
    "grid_search.fit(trainingX_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "tight-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "built-elimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 100,\n",
       " 'oob_score': True}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-brief",
   "metadata": {},
   "source": [
    "Fitting a random forest with the best parameters from the gridsearch applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "federal-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting random forest with bet vross-validation parameters\n",
    "Random_forest_model = RandomForestClassifier(n_estimators = 100,\n",
    "                                             random_state = 42,\n",
    "                                             oob_score=True,\n",
    "                                             max_depth = 10,\n",
    "                                             max_features = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "theoretical-roman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 8.08 s, total: 1min 17s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "Random_forest_model.fit(trainingX_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "lonely-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix to check if accuracy has been improved.\n",
    "y_predicted = pd.DataFrame(Random_forest_model.predict(testingX_data))\n",
    "# Calling function to write the csv file\n",
    "convert_prediction_format(y_predicted, testing_data[['id']], 'random-forest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-azerbaijan",
   "metadata": {},
   "source": [
    "Accuracy with new random forest parameters is: ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "naked-encounter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using the training data for prediction is  0.8402966666666667\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy for training with considering the OOB sample\n",
    "print(\"Accuracy score using the training data for prediction is \", \n",
    "      Random_forest_model.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-exemption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-current",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-accent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-conditions",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-remains",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-disney",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "upset-awareness",
   "metadata": {},
   "source": [
    "*Bagging Classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "temporal-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a bagging classifier with decision tree\n",
    "Bagging_model = BaggingClassifier(DecisionTreeClassifier(random_state=42), n_estimators=100,\n",
    "    max_samples=100, bootstrap=True, random_state=42, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "liberal-cabin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 11s, sys: 2min 17s, total: 8min 29s\n",
      "Wall time: 8min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=42),\n",
       "                  max_samples=100, n_estimators=100, oob_score=True,\n",
       "                  random_state=42)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fitting the bagging classifier.\n",
    "Bagging_model.fit(trainingX_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "broadband-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "y_predicted = pd.DataFrame(Bagging_model.predict(testingX_data))\n",
    "# Calling function to write the csv file\n",
    "convert_prediction_format(y_predicted, testing_data[['id']], 'bagging.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-blowing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "descending-saturday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using the training data for prediction is  0.8331966666666667\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy for training with considering the OOB sample\n",
    "print(\"Accuracy score using the training data for prediction is \", \n",
    "      Bagging_model.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-absolute",
   "metadata": {},
   "source": [
    "The accuracy score here using the testing data indicate we might be overfitting seeing the training data performs 8% better in terms of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-despite",
   "metadata": {},
   "source": [
    "######  [3] Fitting 3 models to assess begininng state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-private",
   "metadata": {},
   "source": [
    "*Random Forest*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-running",
   "metadata": {},
   "source": [
    "*Bagging? Ensembe?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-cannon",
   "metadata": {},
   "source": [
    "###### [4] Overfit/Underfit trade-off of best perfoming mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-investing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-scheduling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "instructional-marriage",
   "metadata": {},
   "source": [
    "###### [5] Feature importance on the best perfoming model and reduce complexity (overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-cooperation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-dairy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-password",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-planner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ranging-commissioner",
   "metadata": {},
   "source": [
    "###### [6] Tuning hyperparameters of best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-beijing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-extent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-chaos",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-arrow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "driving-accountability",
   "metadata": {},
   "source": [
    "###### [7] Results of the best perfoming model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-seven",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
