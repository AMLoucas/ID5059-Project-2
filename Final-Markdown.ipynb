{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "musical-botswana",
   "metadata": {},
   "source": [
    "# Classification Assesment Technical Report\n",
    "\n",
    "\n",
    "## To run the code:\n",
    "\n",
    " * Make sure all data being used is in the appropriate path(data/..)\n",
    " * Using the correct python version (>3) \n",
    " * Make sure all the libraries being used are installed on your machine.\n",
    "\n",
    "## Workflow implemented for this assesment :\n",
    "        \n",
    " 1. Import data in the enviroment\n",
    " 2. Exploration analysis and summary statistics\n",
    "  * Structure Checking\n",
    "  * Features correlated with respone ('target')\n",
    "  * Feature Visualisation Overview\n",
    " 3. Explore 3 candidate models\n",
    "  * Fit models on full dataset\n",
    "  * Reduce dimnesions of training\n",
    "  * Fit models on reduced dimensions\n",
    "  * Reduced Dimensions further explored\n",
    "  * Hyperparameter tuning\n",
    " 4. Compare final results\n",
    " 5. Number of covariate with Accuracy trade-off\n",
    "  * Fit XGBoost Classifier with different number of covariates\n",
    "  * Plot the Acuuracy with Number of covariates trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-glossary",
   "metadata": {},
   "source": [
    "## [1] Importing the dataset into the python enviroment\n",
    "\n",
    "In this section, the appropriate libraries that will be used in the following process and the datasets used are imported. Please note that all the libraries being imported must be installed on the local machines for the following import statements to be executed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deluxe-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important libraries for data frame manipulations.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys as sys\n",
    "\n",
    "# For fitting logistic regression.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# For fitting a random forest.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For fitting a decision tree.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# For fitting a XGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Importing accuracy_score to auto calculate our classifiers accuracy.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Finding static metrics.\n",
    "import statistics\n",
    "\n",
    "# To apply a gridsearch in hyperparameters for random forest.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# To create graphs/plots to visualisation feature relations.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "relative-commercial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the training and testing set already provided.\n",
    "training_data = pd.read_csv(\"data/train.csv\")\n",
    "testing_data = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-insurance",
   "metadata": {},
   "source": [
    "## [2] Exploration Analysis (applied on the data)\n",
    "\n",
    "### [2.1] Structure checking of training and test\n",
    "\n",
    "This step is fundamental for the construction of our candidate (models) classifiers. It is also important to help confirm that the two datasets we are working on have the same strucuture (covariates). However, this step is undertaken with extreme caution, as the test data must not be viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "micro-violence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Data columns (total 32 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   id      300000 non-null  int64  \n",
      " 1   cat0    300000 non-null  object \n",
      " 2   cat1    300000 non-null  object \n",
      " 3   cat2    300000 non-null  object \n",
      " 4   cat3    300000 non-null  object \n",
      " 5   cat4    300000 non-null  object \n",
      " 6   cat5    300000 non-null  object \n",
      " 7   cat6    300000 non-null  object \n",
      " 8   cat7    300000 non-null  object \n",
      " 9   cat8    300000 non-null  object \n",
      " 10  cat9    300000 non-null  object \n",
      " 11  cat10   300000 non-null  object \n",
      " 12  cat11   300000 non-null  object \n",
      " 13  cat12   300000 non-null  object \n",
      " 14  cat13   300000 non-null  object \n",
      " 15  cat14   300000 non-null  object \n",
      " 16  cat15   300000 non-null  object \n",
      " 17  cat16   300000 non-null  object \n",
      " 18  cat17   300000 non-null  object \n",
      " 19  cat18   300000 non-null  object \n",
      " 20  cont0   300000 non-null  float64\n",
      " 21  cont1   300000 non-null  float64\n",
      " 22  cont2   300000 non-null  float64\n",
      " 23  cont3   300000 non-null  float64\n",
      " 24  cont4   300000 non-null  float64\n",
      " 25  cont5   300000 non-null  float64\n",
      " 26  cont6   300000 non-null  float64\n",
      " 27  cont7   300000 non-null  float64\n",
      " 28  cont8   300000 non-null  float64\n",
      " 29  cont9   300000 non-null  float64\n",
      " 30  cont10  300000 non-null  float64\n",
      " 31  target  300000 non-null  int64  \n",
      "dtypes: float64(11), int64(2), object(19)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Having info analysis on the training dataset.\n",
    "training_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coastal-salmon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   id      200000 non-null  int64  \n",
      " 1   cat0    200000 non-null  object \n",
      " 2   cat1    200000 non-null  object \n",
      " 3   cat2    200000 non-null  object \n",
      " 4   cat3    200000 non-null  object \n",
      " 5   cat4    200000 non-null  object \n",
      " 6   cat5    200000 non-null  object \n",
      " 7   cat6    200000 non-null  object \n",
      " 8   cat7    200000 non-null  object \n",
      " 9   cat8    200000 non-null  object \n",
      " 10  cat9    200000 non-null  object \n",
      " 11  cat10   200000 non-null  object \n",
      " 12  cat11   200000 non-null  object \n",
      " 13  cat12   200000 non-null  object \n",
      " 14  cat13   200000 non-null  object \n",
      " 15  cat14   200000 non-null  object \n",
      " 16  cat15   200000 non-null  object \n",
      " 17  cat16   200000 non-null  object \n",
      " 18  cat17   200000 non-null  object \n",
      " 19  cat18   200000 non-null  object \n",
      " 20  cont0   200000 non-null  float64\n",
      " 21  cont1   200000 non-null  float64\n",
      " 22  cont2   200000 non-null  float64\n",
      " 23  cont3   200000 non-null  float64\n",
      " 24  cont4   200000 non-null  float64\n",
      " 25  cont5   200000 non-null  float64\n",
      " 26  cont6   200000 non-null  float64\n",
      " 27  cont7   200000 non-null  float64\n",
      " 28  cont8   200000 non-null  float64\n",
      " 29  cont9   200000 non-null  float64\n",
      " 30  cont10  200000 non-null  float64\n",
      "dtypes: float64(11), int64(1), object(19)\n",
      "memory usage: 47.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Having info analysis on the testing dataset\n",
    "testing_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-equation",
   "metadata": {},
   "source": [
    "From the results displayed in the above cells, we can confirm that the two datasets do not hold any null values and they are of the same design and structure.\n",
    "\n",
    "<br>\n",
    "\n",
    "Following are the insights gathered from this initial analysis:\n",
    " * Both datasets contain 19 factor type covariates\n",
    " * Both datasets contain 11 float type covariates\n",
    " * The training dataset has 1 extra column of type int which is the response variable of our training dataset\n",
    " * The training set consists of 300K rows\n",
    " * The testing set consists of 200K rows\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-california",
   "metadata": {},
   "source": [
    "Our next step is to check the different levels for each factor covariate. The reason behind this action is that in Python the testing and training set must have the exact number of factor levels for the identical covariate. When we apply 1-hot-encoder, each level will act as a unique covariate. With this being said if one factor covariate has different number of levels between the two sets, the design structure will not be correct.\n",
    "\n",
    "**1-Hot-Encoder** is a method used in Python to overcome the different levels of the categorical (string) columns of the data. Given that Python models only understand numerical values, we need to convert the string data to numerical without implementing a mathematical meaning to them. This technique creates a new column for **each** different level and fills the cells with **binary values** (1 = true, 0 = false). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "returning-purpose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>cat11</th>\n",
       "      <th>cat12</th>\n",
       "      <th>cat13</th>\n",
       "      <th>cat14</th>\n",
       "      <th>cat15</th>\n",
       "      <th>cat16</th>\n",
       "      <th>cat17</th>\n",
       "      <th>cat18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>51</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>299</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>AH</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>DJ</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>223525</td>\n",
       "      <td>90809</td>\n",
       "      <td>168694</td>\n",
       "      <td>187251</td>\n",
       "      <td>129385</td>\n",
       "      <td>238563</td>\n",
       "      <td>187896</td>\n",
       "      <td>45818</td>\n",
       "      <td>42380</td>\n",
       "      <td>201945</td>\n",
       "      <td>31584</td>\n",
       "      <td>258932</td>\n",
       "      <td>257139</td>\n",
       "      <td>292712</td>\n",
       "      <td>160166</td>\n",
       "      <td>203574</td>\n",
       "      <td>206906</td>\n",
       "      <td>247125</td>\n",
       "      <td>255482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cat0    cat1    cat2    cat3    cat4    cat5    cat6    cat7  \\\n",
       "count   300000  300000  300000  300000  300000  300000  300000  300000   \n",
       "unique       2      15      19      13      20      84      16      51   \n",
       "top          A       I       A       A       E      BI       A      AH   \n",
       "freq    223525   90809  168694  187251  129385  238563  187896   45818   \n",
       "\n",
       "          cat8    cat9   cat10   cat11   cat12   cat13   cat14   cat15  \\\n",
       "count   300000  300000  300000  300000  300000  300000  300000  300000   \n",
       "unique      61      19     299       2       2       2       2       4   \n",
       "top         BM       A      DJ       A       A       A       A       B   \n",
       "freq     42380  201945   31584  258932  257139  292712  160166  203574   \n",
       "\n",
       "         cat16   cat17   cat18  \n",
       "count   300000  300000  300000  \n",
       "unique       4       4       4  \n",
       "top          D       D       B  \n",
       "freq    206906  247125  255482  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using describe function to check the levels of the categories in training dataset.\n",
    "training_data.describe(include=[object])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "standing-shape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>cat11</th>\n",
       "      <th>cat12</th>\n",
       "      <th>cat13</th>\n",
       "      <th>cat14</th>\n",
       "      <th>cat15</th>\n",
       "      <th>cat16</th>\n",
       "      <th>cat17</th>\n",
       "      <th>cat18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>51</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>295</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>AH</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>DJ</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>149023</td>\n",
       "      <td>60152</td>\n",
       "      <td>112465</td>\n",
       "      <td>124506</td>\n",
       "      <td>86073</td>\n",
       "      <td>158916</td>\n",
       "      <td>125098</td>\n",
       "      <td>30593</td>\n",
       "      <td>28368</td>\n",
       "      <td>134223</td>\n",
       "      <td>21166</td>\n",
       "      <td>172586</td>\n",
       "      <td>171098</td>\n",
       "      <td>195016</td>\n",
       "      <td>106607</td>\n",
       "      <td>135542</td>\n",
       "      <td>137908</td>\n",
       "      <td>165066</td>\n",
       "      <td>170068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cat0    cat1    cat2    cat3    cat4    cat5    cat6    cat7  \\\n",
       "count   200000  200000  200000  200000  200000  200000  200000  200000   \n",
       "unique       2      15      19      13      20      84      16      51   \n",
       "top          A       I       A       A       E      BI       A      AH   \n",
       "freq    149023   60152  112465  124506   86073  158916  125098   30593   \n",
       "\n",
       "          cat8    cat9   cat10   cat11   cat12   cat13   cat14   cat15  \\\n",
       "count   200000  200000  200000  200000  200000  200000  200000  200000   \n",
       "unique      61      19     295       2       2       2       2       4   \n",
       "top         BM       A      DJ       A       A       A       A       B   \n",
       "freq     28368  134223   21166  172586  171098  195016  106607  135542   \n",
       "\n",
       "         cat16   cat17   cat18  \n",
       "count   200000  200000  200000  \n",
       "unique       4       4       4  \n",
       "top          D       D       B  \n",
       "freq    137908  165066  170068  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using describe function to check the levels of categories in testing dataset.\n",
    "testing_data.describe(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-condition",
   "metadata": {},
   "source": [
    "From the tabular results displayed above, we can comprehend that column 'cat10' in the testing dataset has 4 extra unique values. For this reason we will need to 1-hot-encode the categorical data for both datasets together and split them again to the beginning states.\n",
    "\n",
    "Before we merge the two datasets and ecnode them, we need to isolate the response in the training dataset alone. Additionally we need to remove the index column from the data, because it should not be used in the training or predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "liberal-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a copy of data frames to 1-hot-encode\n",
    "\n",
    "## TRAINING DATA\n",
    "train_encoder = training_data.copy()\n",
    "# Need to drop response varibale from training and hold it seperate.\n",
    "trainY_response = training_data['target'].copy()\n",
    "train_encoder.drop('target', axis = 1, inplace = True)\n",
    "# We also need to remove the index variables because they should not be considered in the model training\n",
    "train_encoder.drop('id', axis = 1, inplace = True)\n",
    "\n",
    "## TESTING DATA\n",
    "test_encoder = testing_data.copy()\n",
    "test_encoder.drop('id', axis = 1, inplace = True)\n",
    "\n",
    "## MERGED DATA\n",
    "# This will concatenate the test data rows below the train data\n",
    "# The first 300K rows will be the train.\n",
    "# The last 200K rows will be the testing.\n",
    "merged_encoder = pd.concat([train_encoder, test_encoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "empty-boutique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "# Using get_dummies() which is the same thing as 1-hot-encoder but ignores numerical values.\n",
    "%time\n",
    "merged_encoder = pd.get_dummies(merged_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "approximate-peace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 500000 entries, 0 to 199999\n",
      "Columns: 642 entries, cont0 to cat18_D\n",
      "dtypes: float64(11), uint8(631)\n",
      "memory usage: 346.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Checking if the one hot encoder worked.\n",
    "merged_encoder.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-greek",
   "metadata": {},
   "source": [
    "From the above result we can see that our data has become a large sparse matrix of values (from 30 columns to 642 columns). This is one of the consequences of using the 1-Hot-Encoder technique. \n",
    "\n",
    "The next step is to split the combined dataset back to training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "distinguished-trading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 300000 entries, 0 to 299999\n",
      "Columns: 642 entries, cont0 to cat18_D\n",
      "dtypes: float64(11), uint8(631)\n",
      "memory usage: 208.0 MB\n"
     ]
    }
   ],
   "source": [
    "# First 300K rows is our training set.\n",
    "trainingX_data = merged_encoder.iloc[:300000,:].copy()\n",
    "trainingX_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "correct-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200000 entries, 0 to 199999\n",
      "Columns: 642 entries, cont0 to cat18_D\n",
      "dtypes: float64(11), uint8(631)\n",
      "memory usage: 138.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Last 200K rows is our testing set.\n",
    "testingX_data = merged_encoder.iloc[300000:,:].copy()\n",
    "testingX_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-affiliation",
   "metadata": {},
   "source": [
    "### [2.2] Correlation relation with response 'target'\n",
    "This section explores possible correlation relations between the covariates and the response variable. This will help us identify the covariates that influence the response value the most. The covariates that influence the response values the most are also assumed to be the most important covariates to be consider while training our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "infinite-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the trainingX_data with trainY_data to see the correlations\n",
    "training_all = pd.concat([trainingX_data.copy(), trainY_response.copy()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pleasant-computer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 7s, sys: 1.07 s, total: 4min 8s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Computing correlation relations.\n",
    "training_corr_influnce = training_all.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "boring-artwork",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target     1.000000\n",
       "cat16_B    0.522759\n",
       "cat15_D    0.467675\n",
       "cat14_B    0.302301\n",
       "cat18_D    0.299653\n",
       "cat11_B    0.285503\n",
       "cat0_A     0.268109\n",
       "cat18_C    0.260021\n",
       "cat17_C    0.237540\n",
       "cont5      0.215184\n",
       "cat2_Q     0.213173\n",
       "cat13_B    0.205714\n",
       "cat8_K     0.194427\n",
       "cat1_L     0.190920\n",
       "cont6      0.189832\n",
       "cont8      0.183726\n",
       "cont1      0.164655\n",
       "cat7_AF    0.160744\n",
       "cat9_A     0.156035\n",
       "cat4_H     0.153590\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the correlation with response in sorted way (20 most positive influential features).\n",
    "training_corr_influnce[\"target\"].sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mental-repair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat16_D    -0.505020\n",
       "cat15_B    -0.435327\n",
       "cat18_B    -0.409153\n",
       "cat14_A    -0.302301\n",
       "cat11_A    -0.285503\n",
       "cat0_B     -0.268109\n",
       "cat17_D    -0.267343\n",
       "cat13_A    -0.205714\n",
       "cat1_I     -0.198141\n",
       "cat4_E     -0.165314\n",
       "cat6_A     -0.149729\n",
       "cont3      -0.148316\n",
       "cat2_A     -0.141533\n",
       "cat9_E     -0.126067\n",
       "cat10_CR   -0.100503\n",
       "cat1_A     -0.095467\n",
       "cat2_C     -0.093678\n",
       "cat12_B    -0.083143\n",
       "cont4      -0.075585\n",
       "cat7_E     -0.075031\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the correlation with response in sorted way (20 most negative influential).\n",
    "training_corr_influnce[\"target\"].sort_values(ascending=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-magnet",
   "metadata": {},
   "source": [
    "From the results above we can see some values are close to 0, which indicates that they do not influence the response variable. Following this, further investigation on feature importance is conducted.\n",
    "\n",
    "### [2.3] Feature Visualisation Overview\n",
    "\n",
    "In this section, the visualisation aspects of our covariates is explored. This process will help us identify the key features that help in predicting the response target. We implement a few graphs concerning our top correlated features from the above analysis. For extra insights and visualisation overview you can visit [Full Visualisation Overview](http://localhost:8888/notebooks/EDA.ipynb)\n",
    "\n",
    "We begin by visualizing the proportion that dictates the response target variable, to examine which values are expected to be predicted the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adult-breakfast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subset of the data when target is one(TRUE) is (79461, 32) \n",
      "The subset of the data when target is zero(FALSE) is (220539, 32) \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_target_one = training_data[training_data['target'] == 1]\n",
    "print(\"The subset of the data when target is one(TRUE) is {} \".format(data_target_one.shape))\n",
    "data_target_zero = training_data[training_data['target'] == 0]\n",
    "print(\"The subset of the data when target is zero(FALSE) is {} \".format(data_target_zero.shape))\n",
    "\n",
    "sns.countplot(data =training_data, x='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-plumbing",
   "metadata": {},
   "source": [
    "From the graph displayed above, it is clear that most of the data is constructed with 0-value responses. There are 220K rows whose response is 0, while the 1-value responses are 80K rows. More than 2/3 of the data is being dictated by 0-value response. \n",
    "\n",
    "By plotting the most influential in terms of correlation features, we can check their relations.The following features will be examined:\n",
    " \n",
    " * cat16\n",
    " * cat15\n",
    " * cat18\n",
    " * cat14\n",
    " * cont5\n",
    " \n",
    "For more visualisations, please visit the attached document provided [EDA](....)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-tension",
   "metadata": {},
   "source": [
    "* **cat16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "floppy-alias",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cat16 plots\n",
    "sns.countplot(data =data_target_one, x='cat16').set_title('1-response data')\n",
    "plt.show()\n",
    "sns.countplot(data =data_target_zero, x='cat16').set_title('0-response data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-banking",
   "metadata": {},
   "source": [
    "**cat16 =>** From the two plots displayed above, we observe that level B of cat16 is highly correlated with the repsonse value 1. Since we do not have many response values where 'target=1', cat16 would be beneficial in trying to capture this target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-spelling",
   "metadata": {},
   "source": [
    "* **cat15**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "developing-optics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcKElEQVR4nO3dfbxdVX3n8c/X8CAVIoEEGkgwqAEHUINEzPhIYYRArUEHKekoEamBAnboWAWdmcJQmeL4gEURDENK4ksJCCKpBpEBhdYaJBEEgiCXCJIYSEh4FAQD3/ljr0s313uTm5B1Dvfm+3699uvs89tr7b324cX9Zj+cfWSbiIiITe1l3R5AREQMTwmYiIioIgETERFVJGAiIqKKBExERFSRgImIiCoSMBHxPEkTJFnSFt0eSwx9CZjYLEjaQdIVkn4r6T5Jf9HtMQ11kg6QtKzb44iXrvwrJTYX5wLPADsDk4DvSfq57SXr6yhpC9trK48vYtjJEUwMe5JeAfxn4H/afsL2vwLzgQ+to48lnSjpbuDuUnuPpFskPSLp3yS9odX+FEnLJT0u6S5JB5X66ZIuk3RJWfYzSW9s9fsPkn5U1rlE0ntbyy6SdK6k75W+N0p6TVkmSWdLWinpMUm3SdqnLNta0ucl/VrSg5LOl7TNAPs5orR9SNJS4E/7LD9G0i/K9pdKOq71mV4F7CLpiTLtIml/ST8p+7NC0lckbbUh/71i+EjAxOZgD2Ct7V+2aj8H9l5Pv8OBtwB7SdoXmA0cB+wIfA2YX/6Y7wmcBLzZ9nbAIcC9rfVMA74F7AB8E/iOpC0lbQn8M/ADYCfgY8A3yvp6HQX8L2AU0AOcWeoHA+8s+/ZK4EhgdVl2VqlPAl4L7Ar83QD7+FHgPcC+wGTgiD7LV5blI4FjgLMlvcn2b4FDgd/Y3rZMvwGeBf4GGA38R+Ag4IQBth3DXAImNgfbAo/1qT0KbLeefv9ge43tp4CZwNds32j7WdtzgKeBKTR/VLemCaItbd9r+57Wehbbvsz274EvAi8v/aaUsZ1l+xnb1wHfBaa3+l5h+6flFN03aEID4Pdl/K8DZPsXtldIUhnr35SxPw78b5qg6s+RwJds3297DfAP7YW2v2f7HjeupwnDdwz0gdlebHuh7bW276UJ4ncN1D6GtwRMbA6eoPkXeNtI4HGAcmqq9zRP+4/n/a35VwEfL6d+HpH0CDAe2MV2D3AycDqwUtI8Sbv0tx7bzwHLgF3KdH+p9bqP5oij1wOt+SdpAokSRl+huba0UtIsSSOBMcAfAYtb4/x+qfdnlz77eV97oaRDJS2UtKas6zCao5N+SdpD0nclPSDpMZpwG7B9DG8JmNgc/BLYQtLEVu2NwBIA23u3TvP8S6tN+1Hj9wNn2t6+Nf2R7YvLOr5p++00QWTgs62+43tnJL0MGAf8pkzjS63XbsDyweyU7XNs7wfsRXNK7BPAQ8BTwN6tcb7S9rYDrGZFe3xl+71j3Rq4HPg8sLPt7YEFgHqH0M/6zgPuBCbaHgl8utU+NjMJmBj2yvWCbwNnSHqFpLfRXBf5+gas5gLgeElvKRfYXyHpTyVtJ2lPSQeWP8i/o/kD3z4q2U/S+8t3S06mObW2ELiR5qjkk+WazAHAnwHz1jcYSW8uY9kS+G3Z7nPlaOgCmmslO5W2u0o6ZIBVXQr8taRxkkYBp7aWbUVz6m8VsFbSoTTXfno9COwo6ZWt2nY0pyOfkPQ64K/Wty8xfCVgYnNxArANzUXri4G/Gswtyr1sL6K5IP4V4GGaC+4fLou3prmw/hDNKa2dgE+1ul8J/Hnp9yHg/bZ/b/sZmkA5tPT9KnC07TsHMaSRNEHyMM1prdXA58qyU8r4FpbTVP8P2LO/lZR1XE1z08PPaIK4d58fB/6aJoQeBv6C5u673uV30nyWS8vpuF2Avy3tHi/rvmQQ+xLDlPKDYxH1SDodeK3tD3Z7LBGdliOYiIioIgETERFV5BRZRERUkSOYiIioIg+7LEaPHu0JEyZ0exgREUPK4sWLH7Ld7xd5EzDFhAkTWLRoUbeHERExpEi6b6BlOUUWERFVJGAiIqKKBExERFSRgImIiCoSMBERUUUCJiIiqkjAREREFdUCRtJsSSsl3d6qXSLpljLdK+mWUp8g6anWsvNbffaTdJukHknnlJ+ERdIOkq6RdHd5HVXqKu16JN0q6U219jEiIgZW8wjmImBqu2D7z21Psj2J5pfyvt1afE/vMtvHt+rn0fwOx8Qy9a7zVOBa2xOBa/n3H0o6tNV2ZukfEREdVu2b/LZvkDShv2XlKORI4MB1rUPSWGCk7YXl/VzgcOAqml8kPKA0nQP8iOaHlqYBc908xXOhpO0ljbW94sXsz36fmPtiug8riz93dLeHEBFDQLeuwbwDeND23a3a7pJulnS9pHeU2q7AslabZaUGzW+E94bGA8DOrT73D9AnIiI6pFvPIptO81OrvVYAu9leLWk/4DuS9h7symxb0gb/7oCkmTSn0dhtt902tHtERKxDx49gJG0BvJ/Wb3Xbftr26jK/GLgH2ANYDoxrdR9XagAPllNovafSVpb6cmD8AH1ewPYs25NtTx4zpt+HgUZExEbqximy/wTcafv5U1+SxkgaUeZfTXOBfmk5BfaYpCnlus3RwJWl23xgRpmf0ad+dLmbbArw6Iu9/hIRERuu5m3KFwM/AfaUtEzSsWXRUbzw9BjAO4Fby23LlwHH215Tlp0A/F+gh+bI5qpSPwt4t6S7aULrrFJfACwt7S8o/SMiosNq3kU2fYD6h/upXU5z23J/7RcB+/RTXw0c1E/dwIkbONyIiNjE8k3+iIioIgETERFVJGAiIqKKBExERFSRgImIiCoSMBERUUUCJiIiqkjAREREFQmYiIioIgETERFVJGAiIqKKBExERFSRgImIiCoSMBERUUUCJiIiqkjAREREFQmYiIioIgETERFVJGAiIqKKBExERFSRgImIiCqqBYyk2ZJWSrq9VTtd0nJJt5TpsNayT0nqkXSXpENa9aml1iPp1FZ9d0k3lvolkrYq9a3L+56yfEKtfYyIiIHVPIK5CJjaT/1s25PKtABA0l7AUcDepc9XJY2QNAI4FzgU2AuYXtoCfLas67XAw8CxpX4s8HCpn13aRUREh1ULGNs3AGsG2XwaMM/207Z/BfQA+5epx/ZS288A84BpkgQcCFxW+s8BDm+ta06Zvww4qLSPiIgO6sY1mJMk3VpOoY0qtV2B+1ttlpXaQPUdgUdsr+1Tf8G6yvJHS/s/IGmmpEWSFq1aterF71lERDyv0wFzHvAaYBKwAvhCh7f/ArZn2Z5se/KYMWO6OZSIiGGnowFj+0Hbz9p+DriA5hQYwHJgfKvpuFIbqL4a2F7SFn3qL1hXWf7K0j4iIjqoowEjaWzr7fuA3jvM5gNHlTvAdgcmAj8FbgImljvGtqK5EWC+bQM/BI4o/WcAV7bWNaPMHwFcV9pHREQHbbH+JhtH0sXAAcBoScuA04ADJE0CDNwLHAdge4mkS4E7gLXAibafLes5CbgaGAHMtr2kbOIUYJ6kzwA3AxeW+oXA1yX10NxkcFStfYyIiIFVCxjb0/spX9hPrbf9mcCZ/dQXAAv6qS/l30+xteu/Az6wQYONiIhNLt/kj4iIKhIwERFRRQImIiKqSMBEREQVCZiIiKgiARMREVUkYCIioooETEREVJGAiYiIKhIwERFRRQImIiKqSMBEREQVCZiIiKgiARMREVUkYCIioooETEREVJGAiYiIKhIwERFRRQImIiKqSMBEREQV1QJG0mxJKyXd3qp9TtKdkm6VdIWk7Ut9gqSnJN1SpvNbffaTdJukHknnSFKp7yDpGkl3l9dRpa7Srqds50219jEiIgZW8wjmImBqn9o1wD623wD8EvhUa9k9tieV6fhW/Tzgo8DEMvWu81TgWtsTgWvLe4BDW21nlv4REdFh1QLG9g3Amj61H9heW94uBMatax2SxgIjbS+0bWAucHhZPA2YU+bn9KnPdWMhsH1ZT0REdFA3r8F8BLiq9X53STdLul7SO0ptV2BZq82yUgPY2faKMv8AsHOrz/0D9HkBSTMlLZK0aNWqVS9iVyIioq+uBIyk/w6sBb5RSiuA3WzvC/w34JuSRg52feXoxhs6DtuzbE+2PXnMmDEb2j0iItZhi05vUNKHgfcAB5VgwPbTwNNlfrGke4A9gOW88DTauFIDeFDSWNsryimwlaW+HBg/QJ+IiOiQjh7BSJoKfBJ4r+0nW/UxkkaU+VfTXKBfWk6BPSZpSrl77GjgytJtPjCjzM/oUz+63E02BXi0dSotIiI6pNoRjKSLgQOA0ZKWAafR3DW2NXBNudt4Yblj7J3AGZJ+DzwHHG+79waBE2juSNuG5ppN73Wbs4BLJR0L3AccWeoLgMOAHuBJ4Jha+xgREQOrFjC2p/dTvnCAtpcDlw+wbBGwTz/11cBB/dQNnLhBg42IiE0u3+SPiIgqEjAREVFFAiYiIqpIwERERBUJmIiIqCIBExERVSRgIiKiigRMRERUkYCJiIgqEjAREVFFAiYiIqpIwERERBUJmIiIqCIBExERVSRgIiKiigRMRERUkYCJiIgqEjAREVFFAiYiIqpIwERERBVVA0bSbEkrJd3equ0g6RpJd5fXUaUuSedI6pF0q6Q3tfrMKO3vljSjVd9P0m2lzzmStK5tRERE5wwqYCRdO5haPy4CpvapnQpca3sicG15D3AoMLFMM4HzynZ2AE4D3gLsD5zWCozzgI+2+k1dzzYiIqJD1hkwkl5e/sCPljSqHBnsIGkCsOv6Vm77BmBNn/I0YE6ZnwMc3qrPdWMhsL2kscAhwDW219h+GLgGmFqWjbS90LaBuX3W1d82IiKiQ7ZYz/LjgJOBXYDFgEr9MeArG7nNnW2vKPMPADuX+V2B+1vtlpXauurL+qmvaxsREdEh6wwY2/8I/KOkj9n+8qbeuG1L8qZe72C3IWkmzek4dtttt5rDiIjY7KzvCAYA21+W9FZgQruP7bkbsc0HJY21vaKc5lpZ6suB8a1240ptOXBAn/qPSn1cP+3XtY2++zULmAUwefLkqkEXEbG5GexF/q8DnwfeDry5TJM3cpvzgd47wWYAV7bqR5e7yaYAj5bTXFcDB5drQKOAg4Gry7LHJE0pd48d3Wdd/W0jIiI6ZFBHMDRhsle5mD5oki6mOfoYLWkZzd1gZwGXSjoWuA84sjRfABwG9ABPAscA2F4j6e+Bm0q7M2z33jhwAs2datsAV5WJdWwjIiI6ZLABczvwx8CK9TVssz19gEUH9dPWwIkDrGc2MLuf+iJgn37qq/vbRkREdM5gA2Y0cIeknwJP9xZtv7fKqCIiYsgbbMCcXnMQEREx/Az2LrLraw8kIiKGl0EFjKTHgd4L/FsBWwK/tT2y1sAiImJoG+wRzHa98+WW4GnAlFqDioiIoW+Dn6ZcnhX2HZpnhEVERPRrsKfI3t96+zKa78X8rsqIIiJiWBjsXWR/1ppfC9xLc5osIiKiX4O9BnNM7YFERMTwMthnkY2TdEX5dcqVki6XNG79PSMiYnM12Iv8/0TzAMldyvTPpRYREdGvwQbMGNv/ZHttmS4CxlQcV0REDHGDDZjVkj4oaUSZPgisrjmwiIgY2gYbMB+heeT9AzRPVD4C+HClMUVExDAw2NuUzwBm2H4YQNIOND9A9pFaA4uIiKFtsEcwb+gNF2h+BAzYt86QIiJiOBhswLys/Fwx8PwRzGCPfiIiYjM02JD4AvATSd8q7z8AnFlnSBERMRwM9pv8cyUtAg4spffbvqPesCIiYqgb9GmuEigJlYiIGJQNflx/RETEYHQ8YCTtKemW1vSYpJMlnS5peat+WKvPpyT1SLpL0iGt+tRS65F0aqu+u6QbS/0SSVt1ej8jIjZ3HQ8Y23fZnmR7ErAf8CRwRVl8du8y2wsAJO0FHAXsDUwFvtr7RAHgXOBQYC9gemkL8NmyrtcCDwPHdmj3IiKi6PYpsoOAe2zft44204B5tp+2/SugB9i/TD22l9p+BpgHTCs/6XwgcFnpPwc4vNYORERE/7odMEcBF7fenyTpVkmzW9+72RW4v9VmWakNVN8ReMT22j71PyBppqRFkhatWrXqxe9NREQ8r2sBU66LvBfo/W7NecBrgEk0zzv7Qu0x2J5le7LtyWPG5OHQERGbUje/jX8o8DPbDwL0vgJIugD4bnm7HBjf6jeu1BigvhrYXtIW5Sim3T4iIjqkm6fIptM6PSZpbGvZ+4Dby/x84ChJW0vaHZgI/BS4CZhY7hjbiuZ023zbBn5I88RngBnAlVX3JCIi/kBXjmAkvQJ4N3Bcq/x/JE0CDNzbu8z2EkmX0nzJcy1wou1ny3pOAq4GRgCzbS8p6zoFmCfpM8DNwIW19ykiIl6oKwFj+7c0F+PbtQ+to/2Z9PPss3Ir84J+6ktp7jKLiIgu6fZdZBERMUwlYCIioooETEREVJGAiYiIKhIwERFRRQImIiKqSMBEREQVCZiIiKgiARMREVUkYCIioooETEREVJGAiYiIKhIwERFRRQImIiKqSMBEREQVCZiIiKgiARMREVUkYCIioooETEREVJGAiYiIKroWMJLulXSbpFskLSq1HSRdI+nu8jqq1CXpHEk9km6V9KbWemaU9ndLmtGq71fW31P6qvN7GRGx+er2Ecyf2J5ke3J5fypwre2JwLXlPcChwMQyzQTOgyaQgNOAtwD7A6f1hlJp89FWv6n1dyciInp1O2D6mgbMKfNzgMNb9bluLAS2lzQWOAS4xvYa2w8D1wBTy7KRthfaNjC3ta6IiOiAbgaMgR9IWixpZqntbHtFmX8A2LnM7wrc3+q7rNTWVV/WT/0FJM2UtEjSolWrVr3Y/YmIiJYturjtt9teLmkn4BpJd7YX2rYk1xyA7VnALIDJkydX3VZExOama0cwtpeX15XAFTTXUB4sp7corytL8+XA+Fb3caW2rvq4fuoREdEhXQkYSa+QtF3vPHAwcDswH+i9E2wGcGWZnw8cXe4mmwI8Wk6lXQ0cLGlUubh/MHB1WfaYpCnl7rGjW+uKiIgO6NYpsp2BK8qdw1sA37T9fUk3AZdKOha4DziytF8AHAb0AE8CxwDYXiPp74GbSrszbK8p8ycAFwHbAFeVKSIiOqQrAWN7KfDGfuqrgYP6qRs4cYB1zQZm91NfBOzzogcbEREb5aV2m3JERAwTCZiIiKgiARMREVUkYCIioooETEREVJGAiYiIKhIwERFRRQImIiKqSMBEREQVCZiIiKgiARMREVUkYCIioooETEREVJGAiYiIKrr5k8mxGfv1Ga/v9hBeMnb7u9u6PYSIKnIEExERVSRgIiKiigRMRERUkYCJiIgqEjAREVFFxwNG0nhJP5R0h6Qlkv5rqZ8uabmkW8p0WKvPpyT1SLpL0iGt+tRS65F0aqu+u6QbS/0SSVt1di8jIqIbRzBrgY/b3guYApwoaa+y7Gzbk8q0AKAsOwrYG5gKfFXSCEkjgHOBQ4G9gOmt9Xy2rOu1wMPAsZ3auYiIaHQ8YGyvsP2zMv848Atg13V0mQbMs/207V8BPcD+ZeqxvdT2M8A8YJokAQcCl5X+c4DDq+xMREQMqKvXYCRNAPYFbiylkyTdKmm2pFGltitwf6vbslIbqL4j8IjttX3q/W1/pqRFkhatWrVqU+xSREQUXQsYSdsClwMn234MOA94DTAJWAF8ofYYbM+yPdn25DFjxtTeXETEZqUrj4qRtCVNuHzD9rcBbD/YWn4B8N3ydjkwvtV9XKkxQH01sL2kLcpRTLt9RER0SDfuIhNwIfAL219s1ce2mr0PuL3MzweOkrS1pN2BicBPgZuAieWOsa1obgSYb9vAD4EjSv8ZwJU19ykiIv5QN45g3gZ8CLhN0i2l9mmau8AmAQbuBY4DsL1E0qXAHTR3oJ1o+1kASScBVwMjgNm2l5T1nQLMk/QZ4GaaQIuIiA7qeMDY/ldA/SxasI4+ZwJn9lNf0F8/20tp7jKLiIguyTf5IyKiigRMRERUkYCJiIgqEjAREVFFAiYiIqpIwERERBUJmIiIqCIBExERVSRgIiKiigRMRERUkYCJiIgqEjAREVFFAiYiIqroyg+ORcSm9bYvv63bQ3jJ+PHHftztIUSRI5iIiKgiARMREVUkYCIioooETEREVJGAiYiIKhIwERFRRQImIiKqGLYBI2mqpLsk9Ug6tdvjiYjY3AzLL1pKGgGcC7wbWAbcJGm+7Tu6O7KIGAquf+e7uj2El4x33XD9Rvcdrkcw+wM9tpfafgaYB0zr8pgiIjYrst3tMWxyko4Aptr+y/L+Q8BbbJ/Up91MYGZ5uydwV0cHunFGAw91exDDSD7PTSef5aY1VD7PV9ke09+CYXmKbLBszwJmdXscG0LSItuTuz2O4SKf56aTz3LTGg6f53A9RbYcGN96P67UIiKiQ4ZrwNwETJS0u6StgKOA+V0eU0TEZmVYniKzvVbSScDVwAhgtu0lXR7WpjKkTukNAfk8N518lpvWkP88h+VF/oiI6L7heoosIiK6LAETERFVJGCGAEnPSrpF0s8l/UzSW7s9pqGs9XkuKZ/pxyXl/4UXQdLhkizpdd0ey1An6Y8lzZN0j6TFkhZI2qPb49oYuQYzBEh6wva2Zf4Q4NO28yyLjdTn89wJ+CbwY9undXdkQ5ekS4BdgOvyOW48SQL+DZhj+/xSeyMw0va/dHVwGyH/aht6RgIPd3sQw4XtlTRPczip/M8dG0jStsDbgWNpvhIQG+9PgN/3hguA7Z8PxXCBYXqb8jC0jaRbgJcDY4EDuzuc4cX20vKA1J2AB7s9niFoGvB927+UtFrSfrYXd3tQQ9Q+wLD57HIEMzQ8ZXuS7dcBU4G5+dd2vIRMp3mgLOV1ehfHEi8hOYIZYmz/RNJoYAywstvjGQ4kvRp4lnyeG0zSDjRH1K+XZJovNlvSJ5wLvBtjCXBEtwexqeQIZogpd+mMAFZ3eyzDgaQxwPnAV/IHcaMcAXzd9qtsT7A9HvgV8I4uj2uoug7YujzpHQBJb5A0JD/PHMEMDb3XYAAEzLD9bBfHM9T1fp5bAmuBrwNf7OqIhq7pwGf71C4v9Rs6P5yhzbYlvQ/4kqRTgN8B9wInd3NcGyu3KUdERBU5RRYREVUkYCIioooETEREVJGAiYiIKhIwERFRRQIm4iVK0gHtJ2dLemd5mvZaSUf0adv7hOhbJOXnweMlId+DiXjpOgB4gubpugC/Bj4M/G0/bZ+yPakjo4oYpARMRIdJOpomJAzcClwK/A9gK5onNPwXYBvgeOBZSR8EPtb7RF1Jz3Vj3BEbKgET0UGS9qYJk7fafqg8y8vAlPIt7r8EPmn745LOB56w/flBrPrlkhbRPJngLNvfqbUPEYOVgInorAOBb9l+CMD2GkmvBy6RNJbmKOZXG7HeV9leXh7ceZ2k22zfs+mGHbHhcpE/ovu+TPOwzdcDx9H87s8Gsb28vC4FfgTsuykHGLExEjARnXUd8AFJO8Lzj7t/JbC8LJ/Ravs4sN36VihplKSty/xo4G3AHZty0BEbIw+7jOgwSTOAT9D8Bs3NwBXA2TQ/hX0d8GbbB0jaA7gMeA74GM2Tda8ARpX5B2zvXW5l/lpp9zLgS7Yv7OxeRfyhBExERFSRU2QREVFFAiYiIqpIwERERBUJmIiIqCIBExERVSRgIiKiigRMRERU8f8BvZnkleJ5j38AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cat15 plots\n",
    "sns.countplot(data =data_target_one, x='cat15').set_title('1-response data')\n",
    "plt.show()\n",
    "sns.countplot(data =data_target_zero, x='cat15').set_title('0-response data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-haiti",
   "metadata": {},
   "source": [
    "**cat15 =>** From the above data we see that level B is the highest level combined for both responses. However tha majority of its occurence predict the 0-response. The second highest level is 'D' but it seems to predict both values equally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-variety",
   "metadata": {},
   "source": [
    "* **cat18**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "wrapped-division",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cat18\n",
    "sns.countplot(data =data_target_one, x='cat18').set_title('1-response data')\n",
    "plt.show()\n",
    "sns.countplot(data =data_target_zero, x='cat18').set_title('0-response data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-cooking",
   "metadata": {},
   "source": [
    "**cat18 =>** From the above two plots we can observe the same phenomenon as with the other features. Level 'B' dictates the occurence frequency, however it predicts response value 0 more than it predicts response value 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-estonia",
   "metadata": {},
   "source": [
    "* **cat14**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "strong-antarctica",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWqklEQVR4nO3df7RdZX3n8feHRISKCJQ0A0lqnJqpg1qtpIA/2jJYIei0YTpgoToES820oFNXWyt2uopFqbrGoqJWh6koodqIVWraBtMUtI6tKJeKYFSGK0qTCCYQfqrQgt/54zxXj/Em3Dzh3Ety36+1zjp7f59nP/vZWVnnk/3jnKSqkCSpxz4zPQFJ0p7LEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRKRZKEklefJMz0N7PkNEe40kr0gyluSBJO+f6fnsDZIsboEzd6bnokcn/2Job/IN4A3ACcD+u7JhkrlV9eBIZiXtxTwT0V6jqj5aVX8F3DGV/km+nuQ1Sa4HvpVkbpJjkvxTkruSfCHJsUP9z0hyc5J7k3wtyUuG6v+Y5J1J7k7ylSTPH9ru8CRrkmxLMp7k5UNtr0tyWZJVbdwNSZYOtb8myebWduPEuEn2SXJOkq8muaONcchOjvXVSW5N8o0kv7Zd24uSfD7JPUk2JnndUPOn2vtdSe5L8uwkP5Hkqrbf25N8IMlBU/kz197HENFsdxrwIuAgYD7wtwzOZg4Bfhf4SJJ5SR4HXAicWFWPB54DXDc0ztHAV4FDgXOBjw59qK8GNgGHAycDf5zkuKFtf6n1OQhYA7wTIMlPAq8Afqbt8wTg622bVwInAT/fxr0TeNdkB5hkWTuWFwBLgF/Yrsu3gNPb/l8E/GaSk1rbz7X3g6rqgKr6DBDgjW2//xFYBLxusn1r72eIaLa7sKo2VtV3gJcCa6tqbVV9t6rWA2PAC1vf7wJPS7J/Vd1aVRuGxtkCvK2q/q2qPgTcCLwoySLgucBrqur+qroO+DMGH9oTPt32+RBwKfCMVn8IeCxwRJLHVNXXq+qrre03gP9ZVZuq6gEGH+In7+DexYuB91XVF6vqW2z3gV9Vn6yqG9oxXw/8BYNwmlRVjVfV+qp6oKq2AhfsrL/2boaIZoUkV7TLMfdNXIZqNg4tPxE4pV3KuivJXcDzgMPah++vMPjwvjXJ3yZ5ytC2m+sHf830Fgb/Uj8c2FZV927XtmBo/bah5W8D+7V7NOPAqxh86G9JsjrJ4UNzvXxonl9mEDrzJzn8w7c7zlu2+7M5OsknkmxNcnc7xkMnGWei//w2l81J7gH+fGf9tXczRDQrVNWJ7XLMAVX1geGmoeWNwKVVddDQ63FV9aY2xrqqegFwGPAV4P8MbbsgSYbWf5zBjf5vAIckefx2bZunOO8PVtXzGIRGAW8emuuJ2811v6qabNxbGVxyGt7/sA8yuIy2qKqeALyHwSUr+ME/nwl/3OpPr6oDGZzBZZJ+mgUMEe012o3x/YA5wJwk++3io6l/DvxikhOSTGx/bJKF7V/fy9u9kQeA+xhc3prwY8D/SPKYJKcwuFewtqo2Av8EvLGN91PAmW1fD3c8P5nkuCSPBe4HvjO0z/cA5yd5Yus7L8nyHQx1GXBGkiOS/AiDezbDHs/gbOn+JEcBvzrUtrXt899v1/8+4O4kC4BXP9yxaO9liGhv8gcMPmjPYfCv4++02pS0D/zlwO8z+PDcyOADcp/2+m0GZxbbGNwD+M2hzT/L4Kb17cD5wMlVNfGU2GnA4rbt5cC5VfX3U5jSY4E3tTFvYxBUr21tb2dw9vB3Se4FrmZwc3+y47oCeBtwFTDe3oedBZzXxvlDBqEzse232/H8Y7t0dgzwR8CzgLsZPIjw0Skci/ZS8T+lknZPkjOAX2+XnaRZxTMRSVI3Q0SS1M3LWZKkbp6JSJK6zbofYDz00ENr8eLFMz0NSdpjXHvttbdX1bzJ2mZdiCxevJixsbGZnoYk7TGS3LKjNi9nSZK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkrrNum+s764jX71qpqegR6Fr/9fpMz0FaUZ4JiJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqNtIQSfL1JDckuS7JWKsdkmR9kpva+8GtniQXJhlPcn2SZw2Ns6L1vynJiqH6kW388bZtRnk8kqQfNB1nIv+pqp5ZVUvb+jnAlVW1BLiyrQOcCCxpr5XAu2EQOsC5wNHAUcC5E8HT+rx8aLtloz8cSdKEmbictRy4pC1fApw0VF9VA1cDByU5DDgBWF9V26rqTmA9sKy1HVhVV1dVAauGxpIkTYNRh0gBf5fk2iQrW21+Vd3alm8D5rflBcDGoW03tdrO6psmqf+QJCuTjCUZ27p16+4cjyRpyNwRj/+8qtqc5MeA9Um+MtxYVZWkRjwHquoi4CKApUuXjnx/kjRbjPRMpKo2t/ctwOUM7ml8s12Kor1vad03A4uGNl/YajurL5ykLkmaJiMLkSSPS/L4iWXgeOCLwBpg4gmrFcDH2vIa4PT2lNYxwN3tstc64PgkB7cb6scD61rbPUmOaU9lnT40liRpGozyctZ84PL21O1c4INV9fEk1wCXJTkTuAV4ceu/FnghMA58G3gZQFVtS/J64JrW77yq2taWzwLeD+wPXNFekqRpMrIQqaqbgWdMUr8DeP4k9QLO3sFYFwMXT1IfA56225OVJHXxG+uSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSeo28hBJMifJ55P8TVt/UpLPJhlP8qEk+7b6Y9v6eGtfPDTGa1v9xiQnDNWXtdp4knNGfSySpB80HWcivwV8eWj9zcBbq+rJwJ3Ama1+JnBnq7+19SPJEcCpwFOBZcCftmCaA7wLOBE4Ajit9ZUkTZORhkiShcCLgD9r6wGOA/6ydbkEOKktL2/rtPbnt/7LgdVV9UBVfQ0YB45qr/Gqurmq/hVY3fpKkqbJqM9E3gb8HvDdtv6jwF1V9WBb3wQsaMsLgI0Arf3u1v979e222VH9hyRZmWQsydjWrVt385AkSRNGFiJJ/jOwpaquHdU+pqqqLqqqpVW1dN68eTM9HUnaa8wd4djPBX4pyQuB/YADgbcDByWZ2842FgKbW//NwCJgU5K5wBOAO4bqE4a32VFdkjQNRnYmUlWvraqFVbWYwY3xq6rqJcAngJNbtxXAx9rymrZOa7+qqqrVT21Pbz0JWAJ8DrgGWNKe9tq37WPNqI5HkvTDRnkmsiOvAVYneQPweeC9rf5e4NIk48A2BqFAVW1IchnwJeBB4OyqegggySuAdcAc4OKq2jCtRyJJs9y0hEhVfRL4ZFu+mcGTVdv3uR84ZQfbnw+cP0l9LbD2EZyqJGkX+I11SVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndphQiSa6cSk2SNLvM3Vljkv2AHwEOTXIwkNZ0ILBgxHOTJD3K7TREgP8OvAo4HLiW74fIPcA7RzctSdKeYKchUlVvB96e5JVV9Y5pmpMkaQ/xcGciAFTVO5I8B1g8vE1VrRrRvCRJe4AphUiSS4GfAK4DHmrlAgwRSZrFphQiwFLgiKqqUU5GkrRnmer3RL4I/LtRTkSStOeZaogcCnwpybokayZeO9sgyX5JPpfkC0k2JPmjVn9Sks8mGU/yoST7tvpj2/p4a188NNZrW/3GJCcM1Ze12niSc3b56CVJu2Wql7Ne1zH2A8BxVXVfkscAn05yBfDbwFuranWS9wBnAu9u73dW1ZOTnAq8GfiVJEcApwJPZfCo8d8n+Q9tH+8CXgBsAq5JsqaqvtQxV0lSh6k+nfUPuzpwu39yX1t9THsVcBzwq61+CYOAejewnO+H1V8C70ySVl9dVQ8AX0syDhzV+o1X1c0ASVa3voaIJE2Tqf7syb1J7mmv+5M8lOSeKWw3J8l1wBZgPfBV4K6qerB12cT3v/m+ANgI0NrvBn50uL7dNjuqTzaPlUnGkoxt3bp1KocsSZqCKYVIVT2+qg6sqgOB/YH/CvzpFLZ7qKqeCSxkcPbwlN2Ya7equqiqllbV0nnz5s3EFCRpr7TLv+JbA38FnPBwfYe2uQv4BPBs4KAkE5fRFgKb2/JmYBFAa38CcMdwfbttdlSXJE2TqX7Z8JeHVvdh8L2R+x9mm3nAv1XVXUn2Z3AD/M0MwuRkYDWwAvhY22RNW/9Ma7+qqqo9BfbBJBcwuLG+BPgcg9/xWpLkSQzC41S+f69FkjQNpvp01i8OLT8IfJ3BTeydOQy4JMkcBsFzWVX9TZIvAauTvAH4PPDe1v+9wKXtxvk2BqFAVW1IchmDG+YPAmdX1UMASV4BrAPmABdX1YYpHo8k6REw1aezXrarA1fV9cBPT1K/me8/XTVcvx84ZQdjnQ+cP0l9LbB2V+cmSXpkTPXprIVJLk+ypb0+kmThqCcnSXp0m+qN9fcxuGdxeHv9datJkmaxqYbIvKp6X1U92F7vB3xWVpJmuamGyB1JXtq+PDgnyUsZPH4rSZrFphoivwa8GLgNuJXBI7hnjGhOkqQ9xFQf8T0PWFFVdwIkOQR4C4NwkSTNUlM9E/mpiQABqKptTPL4riRpdplqiOyT5OCJlXYmMtWzGEnSXmqqQfAnwGeSfLitn8IkX/6TJM0uU/3G+qokYwz+LxCAX/Y/f5IkTfmSVAsNg0OS9D27/FPwkiRNMEQkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3fwlXmkv8i/nPX2mp6BHoR//wxtGNrZnIpKkboaIJKmbISJJ6maISJK6GSKSpG4jC5Eki5J8IsmXkmxI8lutfkiS9Uluau8Ht3qSXJhkPMn1SZ41NNaK1v+mJCuG6kcmuaFtc2GSjOp4JEk/bJRnIg8Cv1NVRwDHAGcnOQI4B7iyqpYAV7Z1gBOBJe21Eng3DEIHOBc4GjgKOHcieFqflw9tt2yExyNJ2s7IQqSqbq2qf27L9wJfBhYAy4FLWrdLgJPa8nJgVQ1cDRyU5DDgBGB9VW2rqjuB9cCy1nZgVV1dVQWsGhpLkjQNpuWeSJLFwE8DnwXmV9Wtrek2YH5bXgBsHNpsU6vtrL5pkvpk+1+ZZCzJ2NatW3fvYCRJ3zPyEElyAPAR4FVVdc9wWzuDqFHPoaouqqqlVbV03rx5o96dJM0aIw2RJI9hECAfqKqPtvI326Uo2vuWVt8MLBrafGGr7ay+cJK6JGmajPLprADvBb5cVRcMNa0BJp6wWgF8bKh+entK6xjg7nbZax1wfJKD2w3144F1re2eJMe0fZ0+NJYkaRqM8gcYnwv8N+CGJNe12u8DbwIuS3ImcAvw4ta2FnghMA58G3gZQFVtS/J64JrW77yq2taWzwLeD+wPXNFekqRpMrIQqapPAzv63sbzJ+lfwNk7GOti4OJJ6mPA03ZjmpKk3eA31iVJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1G1kIZLk4iRbknxxqHZIkvVJbmrvB7d6klyYZDzJ9UmeNbTNitb/piQrhupHJrmhbXNhkozqWCRJkxvlmcj7gWXb1c4BrqyqJcCVbR3gRGBJe60E3g2D0AHOBY4GjgLOnQie1uflQ9ttvy9J0oiNLESq6lPAtu3Ky4FL2vIlwElD9VU1cDVwUJLDgBOA9VW1raruBNYDy1rbgVV1dVUVsGpoLEnSNJnueyLzq+rWtnwbML8tLwA2DvXb1Go7q2+apD6pJCuTjCUZ27p16+4dgSTpe2bsxno7g6hp2tdFVbW0qpbOmzdvOnYpSbPCdIfIN9ulKNr7llbfDCwa6rew1XZWXzhJXZI0jaY7RNYAE09YrQA+NlQ/vT2ldQxwd7vstQ44PsnB7Yb68cC61nZPkmPaU1mnD40lSZomc0c1cJK/AI4FDk2yicFTVm8CLktyJnAL8OLWfS3wQmAc+DbwMoCq2pbk9cA1rd95VTVxs/4sBk+A7Q9c0V6SpGk0shCpqtN20PT8SfoWcPYOxrkYuHiS+hjwtN2ZoyRp9/iNdUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEnd9vgQSbIsyY1JxpOcM9PzkaTZZI8OkSRzgHcBJwJHAKclOWJmZyVJs8ceHSLAUcB4Vd1cVf8KrAaWz/CcJGnWmDvTE9hNC4CNQ+ubgKO375RkJbCyrd6X5MZpmNtscChw+0xP4tEgb1kx01PQD/Pv54Rzs7sjPHFHDXt6iExJVV0EXDTT89jbJBmrqqUzPQ9pMv79nB57+uWszcCiofWFrSZJmgZ7eohcAyxJ8qQk+wKnAmtmeE6SNGvs0ZezqurBJK8A1gFzgIurasMMT2s28RKhHs38+zkNUlUzPQdJ0h5qT7+cJUmaQYaIJKmbIaJdluShJNcl+UKSf07ynJmekzQhyUlJKslTZnous4Ehoh7fqapnVtUzgNcCb5zpCUlDTgM+3d41YoaIdteBwJ0zPQkJIMkBwPOAMxk88q8R26Mf8dWM2T/JdcB+wGHAcTM7Hel7lgMfr6r/l+SOJEdW1bUzPam9mWci6jFxOespwDJgVZLd/nEe6RFwGoMfYqW9e0lrxPyeiHZZkvuq6oCh9W8CT6+qLTM4Lc1ySQ5h8COsW4Fi8AXkAp5YftCNjGci2i3tCZg5wB0zPRfNeicDl1bVE6tqcVUtAr4G/OwMz2uv5j0R9Zi4JwIQYEVVPTSD85FgcOnqzdvVPtLqn5r+6cwOXs6SJHXzcpYkqZshIknqZohIkroZIpKkboaIJKmbISLNoCTHDv8KcpKfa7+M/GCSkyfpf2CSTUneOb0zlSZniEgz61hg+Kf0/wU4A/jgDvq/Hr/zoEcRv2wojUCS04HfZfCzG9cDlwF/AOzL4Nv9LwH2B34DeCjJS4FXVtX/bdt/d5IxjwTmAx8Hlk7DYUgPyxCRHmFJnsogMJ5TVbe333Qq4JiqqiS/DvxeVf1OkvcA91XVWx5mzH2APwFeCvzCiA9BmjJDRHrkHQd8uKpuB6iqbUmeDnwoyWEMzka+totjngWsrapN/mCyHk0MEWl6vAO4oKrWJDkWeN0ubv9s4GeTnAUcAOzbfk35nEd0ltIuMkSkR95VwOVJLqiqO9rlrCcAm1v7iqG+9zL43yF3qqpeMrGc5AxgqQGiRwOfzpIeYVW1ATgf+IckXwAuYHDm8eEk1wK3D3X/a+C/JLkuyc8m+Zkkm4BTgP+dZMM0T1/aJf6KrySpm2cikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6vb/AXEClvfGDSBsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cat14 \n",
    "sns.countplot(data =data_target_one, x='cat14').set_title('1-response data')\n",
    "plt.show()\n",
    "sns.countplot(data =data_target_zero, x='cat14').set_title('0-response data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-cement",
   "metadata": {},
   "source": [
    "**cat14 =>** From the above plots we can observe that we only have 2 levels for this feature. The differences between them are not significantly large as in other features. Both attributes mostly predict 0-response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-trademark",
   "metadata": {},
   "source": [
    "* **cont5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ceramic-turning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=data_target_one, x=\"cont5\").set_title('1-response data')\n",
    "plt.show()\n",
    "sns.histplot(data=data_target_zero, x=\"cont5\").set_title('0-response data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-circumstances",
   "metadata": {},
   "source": [
    "**cont5 =>** From the two plots above, we can observe that the predictions are more or less the same (Note: axes have different scales). In both cases, it appears that the data is being distributed the same. However, most values lie in the response-1 value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-geology",
   "metadata": {},
   "source": [
    "**One-Hot-Encoding** and **Correlation analysis of the response** (as an indication of what features will be valuable in our training) has now been completed.\n",
    "\n",
    "A brief summary of the dataframes available at this point:   \n",
    " 1. Before One-Hot-Encoding the Datasets\n",
    "  * **training_data** = Full training dataset\n",
    "  * **testing_data** = Full testing dataset\n",
    " 2. After One-Hot-Encoding the Datasets\n",
    "  * **merged_encoder** = Both (training and testing) datasets merged and encoded\n",
    "  * **trainingX_data** = Training dataset explanatory variables (values used for training)\n",
    "  * **trainY_response** = Training dataset response variable (value used to train models under construction)\n",
    "  * **testingX_data** = Testing dataset explanatory variables (values used for predictions)\n",
    " 3. Other Datasets (created during analysis)\n",
    "  * **training_corr_influnce** = Holds correlation values between variables\n",
    "  * **training_all** = Holds the 1-Hot-Encoded explanatory variables with the response, to calculate correlations\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-insert",
   "metadata": {},
   "source": [
    "## [3] Explore candidate models\n",
    "\n",
    "To check the accuracy score of our candidate models we will be modifying the 'target' column with the predicted probabilities produced by our candiated models, as per the requirements. \n",
    "\n",
    "Note: The prediction results must be in probability format, because the evaluation metric is done by a ROC CURVE with a threshold. For this reason the function '.predict_prob()' is used to predict the response target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "silver-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the submittion structure csv, to modify and submit\n",
    "# informing index column to keep correct structure.\n",
    "submit_file = pd.read_csv(\"data/sample_submission.csv\", index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-reason",
   "metadata": {},
   "source": [
    "### [3.1] Fit candidate models on the full dataset\n",
    "\n",
    "Based on our research, the following three models were chosen for this dataset.\n",
    "\n",
    " * **Random Forest**\n",
    " \n",
    "*Random forest is one of the three models that were handpicked to be used for this dataset. This model is a commonly used classification algorithm that can be used for both classification and regression tasks. It also works well with large data sets similar to the one we are using. As the name suggests, the random forest algorithm is a collection of decision trees. It has access to all the hyperparameters available for a decision tree model and bagging classifier, giving more control over the model creation. Given that the model merges multiple decision trees and works to produce the average of the result obtained, it generates stable and accurate results through cross validation.*\n",
    " \n",
    " \n",
    "In the following section, the Random Forest model is fitted using the full dataset consisting of 300K rows and 642 columns. The test dataset will be used to check the accuracy score of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "leading-lucas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 53s, sys: 12.4 s, total: 4min 5s\n",
      "Wall time: 4min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Instantiate model with 100 decision trees \n",
    "# oob_score needs to be true to consider out of bag sampling.\n",
    "Random_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42, oob_score=True)\n",
    "Random_forest_model.fit(trainingX_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "occasional-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "# we choose the 2nd column of results which is the prob predicted.\n",
    "y_predicted = Random_forest_model.predict_proba(testingX_data)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('full-forest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-amsterdam",
   "metadata": {},
   "source": [
    "<font color=\"blue\"> The random forest model has resulted in an accuracy score of **88.22%** on the test data.<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-rider",
   "metadata": {},
   "source": [
    "This will now be compared with the out of bag error produced from the model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "statutory-turner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using the training data for prediction is  0.8458966666666666\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy for training with considering the OOB sample\n",
    "print(\"Accuracy score using the training data for prediction is \", \n",
    "      Random_forest_model.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-advertiser",
   "metadata": {},
   "source": [
    "<font color=\"blue\"> Results from the above cell states that the training set prediction has an accuracy score of **84.5%** which is **4% lower** than the test dataset accuracy score. <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-attempt",
   "metadata": {},
   "source": [
    " * **Logistic Regression**\n",
    " \n",
    "*This model is often used in dealing with supervised classification by generating probabilities efficiently. Results of this model are easy to interpret. Moreover, it has the advantages of being less inclined to overfitting and limits multicollinearity while fitting the classifier. Unfortunately, it does not perform well when the feature space is large, notably across extremely large datasets, particularly if categorical variables are numerous. Additionally, the violation of underlying assumptions, especially linearity on the link scale and independence of observations, might be cause of concern.*\n",
    "\n",
    "In the following section, the Logistic Regression model is fitted using the full dataset consisting of 300K rows and 642 columns. The test dataset will be used to check the accuracy score of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "rough-latex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 5s, sys: 3.44 s, total: 5min 9s\n",
      "Wall time: 5min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42, solver='saga')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Constructing a logistic regression.\n",
    "log_reg = LogisticRegression(solver=\"saga\", max_iter= 1000, random_state=42)\n",
    "# Fitting the logistic regression\n",
    "log_reg.fit(trainingX_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "assisted-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "# we choose the 2nd column of results which is the prob predicted.\n",
    "y_predicted = log_reg.predict_proba(testingX_data)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('full-logistic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-demand",
   "metadata": {},
   "source": [
    "<font color=\"blue\"> The logistic regression model has resulted in an accuracy score of **87.736%** on the test data.<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-vatican",
   "metadata": {},
   "source": [
    " This will now be compared with the accuracy of the training data predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "later-functionality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using the training data for prediction is 0.8450233333333333 %\n"
     ]
    }
   ],
   "source": [
    "# We will see how it performs with training data\n",
    "train_predicted = log_reg.predict(trainingX_data)\n",
    "# Calculating the accuracy\n",
    "print(\"Accuracy score using the training data for prediction is {} %\".format(accuracy_score(trainY_response, train_predicted, normalize=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-vampire",
   "metadata": {},
   "source": [
    "<font color=\"blue\"> Results from the above cell states that the training set prediction has an accuracy score of **84.5%** which is **3.5% lower** than the test dataset accuracy score. <font> However, it is important to note that the threshold used might be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-brother",
   "metadata": {},
   "source": [
    " * **XGBClassifier**\n",
    "\n",
    "*XGB (short for eXtreme Gradient Boosting) is a relatively new model optimized for quick interpretations and quality model performance. Due to its high performance results, XGB models have been used recently to win numerous Kaggle competitions. XGB models are able to operate efficiently on large datasets with the only drawback being that due to the complexity of the model, fine tuning for optimal results can be difficult to achieve. Irrespective of that, we chose this model to predict our target response, to ensure that we utilized the foremost technology available to us in this field.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-cabin",
   "metadata": {},
   "source": [
    "In the following section, the XGBClassifier is fitted using the full dataset consisting of 300K rows and 642 columns. The test dataset will be used to check the accuracy score of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "constant-suspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:31:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 26min 19s, sys: 11.6 s, total: 26min 31s\n",
      "Wall time: 8min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "# Constructing the XGBClassifier \n",
    "xgb_model = XGBClassifier(random_state = 42)\n",
    "# Fitting the XGBClassifier on full dataset.\n",
    "xgb_model.fit(trainingX_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "extended-format",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predicting values using the test X matrix\n",
    "# we choose the 2nd column of results which is the prob predicted.\n",
    "y_predicted = xgb_model.predict_proba(testingX_data)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('full-xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-needle",
   "metadata": {},
   "source": [
    "<font color=\"blue\"> The XGBoost Classifier has resulted in an accuracy score of **88.56%** on the test data.<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-rogers",
   "metadata": {},
   "source": [
    "### [3.2] Reducing dimensions by exploring feature importance\n",
    "\n",
    "From the data wrangling and convertions applied above, the final dataset used for fitting and making preditions is a large sparse matrix that consists of 300K rows and 642 columns. This can cause issues in terms of time and computational complexity and can be an issue in the overfit/underfit trade-off in our analysis. For this reason, we have chosen to apply feature important analysis and keep the analysis process with only the features that constribute to our response.\n",
    "\n",
    "Our goal for this assessment of the given dataset is to reduce the dimensions and keep a similar (if not the same) percentage of accuracy for all our models. In the case of having multiple different models that have the same predictive power, it is beneficial to proceed with the less complex ones. Reducing dimensions of the training data also reduces the complexity of the model.\n",
    "\n",
    "Feature importance code and idea was inspired by a [youtube](https://www.youtube.com/watch?v=NPdn3YPkg9w) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "thirty-auditor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34 s, sys: 1.81 s, total: 35.8 s\n",
      "Wall time: 36.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=5059)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fitting a random forest with only 5 trees to get feature importance.\n",
    "DT_feature_importance = DecisionTreeClassifier(criterion='entropy', random_state=5059)\n",
    "DT_feature_importance.fit(trainingX_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "experimental-unemployment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Feature Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>631</td>\n",
       "      <td>cat16_B</td>\n",
       "      <td>0.222815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>cont5</td>\n",
       "      <td>0.068603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>cont1</td>\n",
       "      <td>0.051586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>cont6</td>\n",
       "      <td>0.049698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cont4</td>\n",
       "      <td>0.046975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>392</td>\n",
       "      <td>cat10_DR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>388</td>\n",
       "      <td>cat10_DN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>387</td>\n",
       "      <td>cat10_DM</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>386</td>\n",
       "      <td>cat10_DL</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>321</td>\n",
       "      <td>cat10_AL</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>642 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index   Feature  Feature Score\n",
       "0      631   cat16_B       0.222815\n",
       "1        5     cont5       0.068603\n",
       "2        1     cont1       0.051586\n",
       "3        6     cont6       0.049698\n",
       "4        4     cont4       0.046975\n",
       "..     ...       ...            ...\n",
       "637    392  cat10_DR       0.000000\n",
       "638    388  cat10_DN       0.000000\n",
       "639    387  cat10_DM       0.000000\n",
       "640    386  cat10_DL       0.000000\n",
       "641    321  cat10_AL       0.000000\n",
       "\n",
       "[642 rows x 3 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the features that are important.\n",
    "features = []\n",
    "feature_score = []\n",
    "# Appenind all scores in arrays to create a data frame.\n",
    "for i, column in enumerate(trainingX_data):\n",
    "    features.append(column)\n",
    "    feature_score.append(DT_feature_importance.feature_importances_[i])\n",
    "    \n",
    "# Create a dataframe with these arrays.\n",
    "feature_score_df = zip(features, feature_score)\n",
    "feature_score_df = pd.DataFrame(feature_score_df, columns = ['Feature', 'Feature Score'])\n",
    "\n",
    "# Sort the data frame according to feature score.\n",
    "feature_score_df = feature_score_df.sort_values('Feature Score', ascending=False).reset_index()\n",
    "feature_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "educational-thirty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features that have an impact on Y variables is (434,)\n"
     ]
    }
   ],
   "source": [
    "# Removing all features that 0 influence on the response.\n",
    "feature_keeping = feature_score_df[feature_score_df['Feature Score'] > 0.0]\n",
    "# Keeping the columns that we constribute to the result.\n",
    "feature_keeping = feature_keeping['Feature'].copy()\n",
    "print(\"Number of features that have an impact on Y variables is {}\".format(feature_keeping.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-directive",
   "metadata": {},
   "source": [
    "From the code executed in the aboe cells, it can be observed that over 200 features did not constribute in the decision tree classification while predicting the Y variable. For this reason we will use the above result to reduce the dimensions of the training set that will be used to construct the model.\n",
    "\n",
    "**NOTE** :\n",
    "The changes in the training data dimensions will be implemented on the test data dimensions as well to maintain consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "precise-nashville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial structure of the data was (300000, 642)\n",
      "The new dimensions of our training data is (300000, 434)\n",
      "The new dimensions of our testing data is (200000, 434)\n",
      "We will now check if all the covariates (full columns) have a level that constributes even the slightest in our model\n"
     ]
    }
   ],
   "source": [
    "# Showing the initial dimension state.\n",
    "print(\"The initial structure of the data was {}\".format(trainingX_data.shape))\n",
    "# Reducing the dimensions of the data.\n",
    "reducedX_training = trainingX_data[feature_keeping]\n",
    "reducedX_testing = testingX_data[feature_keeping]\n",
    "\n",
    "# Showing the new dimension state of our data.\n",
    "print(\"The new dimensions of our training data is {}\".format(reducedX_training.shape))\n",
    "print(\"The new dimensions of our testing data is {}\".format(reducedX_testing.shape))\n",
    "print(\"We will now check if all the covariates (full columns) have a level that constributes even the slightest in our model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "unnecessary-reply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of covariates left in the data is 30 \n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary\n",
    "useful_cov = {}\n",
    "# looping through all the columns that offer some importance.\n",
    "for column in reducedX_training.columns :\n",
    "    col = column.split('_')[0]\n",
    "    # Putting them in the list with the number of occurence.\n",
    "    # If column occurs more than once, that means that they have more than 1 level as a whole covariate.\n",
    "    if col in useful_cov:\n",
    "        useful_cov[col] += 1\n",
    "    else:\n",
    "        useful_cov[col] = 1\n",
    "    \n",
    "print(\"Number of covariates left in the data is {} \".format(len(useful_cov.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-judgment",
   "metadata": {},
   "source": [
    "The above result states that the final dataset after the dimension changes will be using atleast one level from the all feature columns in the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-broadcast",
   "metadata": {},
   "source": [
    "### [3.3] Reduced dimension fitting\n",
    "\n",
    "From the above analysis, we have conlcuded that at least 200 features have been scored 0 for feature importance. This indicates that these features do not constribute to predicting our response value 'target'. \n",
    "\n",
    "In the following cells the dataset with the reduced dimensions will be fit on the 3 candidate models. We will then examine if the perfomance has increased or decreased.\n",
    "\n",
    "Datasets used henceforth:\n",
    " \n",
    " * **reducedX_training** = Training dataset that consists of only the influential features\n",
    " * **reducedX_testing** = Testing dataset that consists of only the influential features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-trainer",
   "metadata": {},
   "source": [
    "We begin by fitting the dataset with reduced dimensions on the three models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-crawford",
   "metadata": {},
   "source": [
    "* **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "organized-process",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 9s, sys: 8.03 s, total: 3min 17s\n",
      "Wall time: 3min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Instantiate model with 100 decision trees \n",
    "# oob_score needs to be true to consider out of bag sampling.\n",
    "Random_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42, oob_score=True)\n",
    "Random_forest_model.fit(reducedX_training, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "tough-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "# we choose the 2nd column of results which is the prob predicted.\n",
    "y_predicted = Random_forest_model.predict_proba(reducedX_testing)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('reduced-forest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-tomorrow",
   "metadata": {},
   "source": [
    "After reducing the dimensions by 200 features we see a small decrease in the perfomance of the **Random Forest** model. \n",
    "\n",
    "<font color=\"blue\"> The new **accuracy score is 88.15%** which has a **0.07% decrease** compared to the full dimension dataset. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "trying-nylon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out of bag error produced while training is 0.8459033333333333\n"
     ]
    }
   ],
   "source": [
    "# Printing out of bag sample error during training\n",
    "print(\"The out of bag error produced while training is {}\".format(Random_forest_model.oob_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-enzyme",
   "metadata": {},
   "source": [
    "By running the **Random Forest** on the **reduced dimensions dataset** we see a minor difference in the training and testing prediction scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-manner",
   "metadata": {},
   "source": [
    " * **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "diagnostic-leather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 44s, sys: 1.83 s, total: 3min 46s\n",
      "Wall time: 3min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=123, solver='saga')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Constructing a logistic regression.\n",
    "log_reg = LogisticRegression(solver=\"saga\", max_iter= 1000, random_state=123)\n",
    "# Fitting the logistic regression\n",
    "log_reg.fit(reducedX_training, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "operating-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "# we choose the 2nd column of results which is the prob predicted.\n",
    "y_predicted = log_reg.predict_proba(reducedX_testing)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('reduced-logistic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-citizenship",
   "metadata": {},
   "source": [
    "After reducing the dimensions by 200 features we see a minor decrease in the perfomance of the **Logistic Regression** model. \n",
    "\n",
    "<font color=\"blue\"> The new **accuracy score is 87.715%** which has a **0.01% decrease** compared to the full dimension dataset. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "powerful-colleague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using the training data for prediction is 0.8447133333333333 %\n"
     ]
    }
   ],
   "source": [
    "# We will see how it performs with training data\n",
    "train_predicted = log_reg.predict(reducedX_training)\n",
    "# Calculating the accuracy\n",
    "print(\"Accuracy score using the training data for prediction is {} %\".format(accuracy_score(trainY_response, train_predicted, normalize=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-reverse",
   "metadata": {},
   "source": [
    "By running the **Logistic Regression** model on the **reduced dimensions dataset** we can observe that both errors in [testing, training] have reduced by **0.01% and 0.1% respectively**. This is assumed to be the cost of reducing 200 features to reduce the model complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-settle",
   "metadata": {},
   "source": [
    "* **XGBClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "reliable-spare",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:09:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 18min 46s, sys: 4.66 s, total: 18min 51s\n",
      "Wall time: 5min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "# Constructing the XGBClassifier \n",
    "xgb_model = XGBClassifier(random_state = 42)\n",
    "# Fitting the XGBClassifier on full dataset.\n",
    "xgb_model.fit(reducedX_training, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "threaded-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "# we choose the 2nd column of results which is the prob predicted.\n",
    "y_predicted = xgb_model.predict_proba(reducedX_testing)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('reduced-xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-falls",
   "metadata": {},
   "source": [
    "After reducing the dimensions by 200 features we see a minor decrease in the perfomance of the **XGBoost Classifier** model. \n",
    "\n",
    "<font color=\"blue\"> The new **accuracy score is 88.54%** which has a **0.02% decrease** compared to the full dimension dataset. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-instruction",
   "metadata": {},
   "source": [
    "### [3.4] Reduced dimension fitting further explored.\n",
    "\n",
    "From the above results we obtained by fitting models using reduced dimensions that consisted of only the covariates that contributed to the response variable, we have managed to keep the accuracy levels high and decrease the dimensions by 200 features. \n",
    "\n",
    "We will now further explore the reduction in dimensions, by keeping only the top features that fill 95% of the feature importance. This means that in a new dataset, we will keep the features that explain 95% of the feature importance and we will examine if our models have the same level of perfomance.\n",
    "\n",
    "We will fit our models on the following datasets:\n",
    " \n",
    " * reduced95_training = Training dataset with 95% of feature importance explained\n",
    " * reduced95_testing = Testing dataset with 95% of feature importance explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ceramic-breach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial structure of the data was (300000, 642)\n",
      "The new dimensions of our training data is (300000, 312)\n",
      "The new dimensions of our testing data is (200000, 312)\n"
     ]
    }
   ],
   "source": [
    "# Holding the percentage of feature importance being satisfied.\n",
    "variance = 0\n",
    "col_keep = []\n",
    "# Looping through all the scores for all features.\n",
    "for index, row in feature_score_df.iterrows():\n",
    "    expirement_var = variance\n",
    "    row_score = row['Feature Score']\n",
    "    # When variance has reached 95 do not add more scores, columns.\n",
    "    if ((expirement_var + row_score) <= 0.95):\n",
    "        col_keep.append(row['Feature'])\n",
    "        variance = variance + row_score\n",
    "\n",
    "\n",
    "# Showing the initial dimension state.\n",
    "print(\"The initial structure of the data was {}\".format(trainingX_data.shape))\n",
    "# Reducing the dimensions of the data.\n",
    "reduced95_training = trainingX_data[col_keep]\n",
    "reduced95_testing = testingX_data[col_keep]\n",
    "\n",
    "# Showing the new dimension state of our data.\n",
    "print(\"The new dimensions of our training data is {}\".format(reduced95_training.shape))\n",
    "print(\"The new dimensions of our testing data is {}\".format(reduced95_testing.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-implement",
   "metadata": {},
   "source": [
    " * **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "sought-entertainment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 26s, sys: 7.06 s, total: 2min 33s\n",
      "Wall time: 2min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Instantiate model with 100 decision trees \n",
    "# oob_score needs to be true to consider out of bag sampling.\n",
    "Random_forest_model = RandomForestClassifier(n_estimators = 100, random_state = 42, oob_score=True)\n",
    "Random_forest_model.fit(reduced95_training, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "damaged-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "# we choose the 2nd column of results which is the prob predicted.\n",
    "y_predicted = Random_forest_model.predict_proba(reduced95_testing)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('reduced95-forest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-hebrew",
   "metadata": {},
   "source": [
    "<font color =\" blue\"> By reducing the dimensions from 642 to 312 and we achieve an accuracy score of **88.14%** that is **0.08% lower** than the original score (when all features were used). </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-clark",
   "metadata": {},
   "source": [
    " * **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "beneficial-feelings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 34s, sys: 1.3 s, total: 2min 35s\n",
      "Wall time: 2min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=123, solver='saga')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Constructing a logistic regression.\n",
    "log_reg = LogisticRegression(solver=\"saga\", max_iter= 1000, random_state=123)\n",
    "# Fitting the logistic regression\n",
    "log_reg.fit(reduced95_training, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "adult-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "# we choose the 2nd column of results which is the prob predicted.\n",
    "y_predicted = log_reg.predict_proba(reduced95_testing)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('reduced95-logistic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-while",
   "metadata": {},
   "source": [
    "<font color =\" blue\"> By reducing the dimensions from 642 to 312 and we achieve an accuracy score of **87.401%** that is **0.3% lower** than the original score (when all features were used). </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-preserve",
   "metadata": {},
   "source": [
    " * **XGDBoost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "structured-joshua",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:59:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 13min 59s, sys: 3.36 s, total: 14min 2s\n",
      "Wall time: 4min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "# Constructing the XGBClassifier \n",
    "xgb_model = XGBClassifier(random_state = 42)\n",
    "# Fitting the XGBClassifier on full dataset.\n",
    "xgb_model.fit(reduced95_training, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "# we choose the 2nd column of results reduced95_testing is the prob predicted.\n",
    "y_predicted = xgb_model.predict_proba(reduced95_testing)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('reduced-95-xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-italy",
   "metadata": {},
   "source": [
    "<font color =\" blue\"> By reducing the dimensions from 642 to 312 and we achieve an accuracy score of **88.479%** that is **0.09% lower** than the original score (when all features were used). </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-creation",
   "metadata": {},
   "source": [
    "We have seen a minor decrease across all the models in terms of accuracy when the dimensions were reduced in half. However, owing to the reduction of dimensions the computational cost and time complexity for fitting and running the models has increased significantly. \n",
    "\n",
    "Our analysis supports that the fact that the **trade-off between the accuracy and dimension reduction is worth it**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-thompson",
   "metadata": {},
   "source": [
    "Our next step is to explore which covariates contributed the most and are the most helpful in predicting the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "quarterly-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of covariates left in the data is 30 \n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary\n",
    "useful_cov = {}\n",
    "# looping through all the columns that offer some importance.\n",
    "for column in reduced95_training.columns :\n",
    "    col = column.split('_')[0]\n",
    "    # Putting them in the list with the number of occurence.\n",
    "    # If column occurs more than once, that means that they have more than 1 level as a whole covariate.\n",
    "    if col in useful_cov:\n",
    "        useful_cov[col] += 1\n",
    "    else:\n",
    "        useful_cov[col] = 1\n",
    "    \n",
    "print(\"Number of covariates left in the data is {} \".format(len(useful_cov.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-asset",
   "metadata": {},
   "source": [
    "The code executed in the above cells states that the new dataset still consists of information across all 30 covariates provided initially. \n",
    "\n",
    "Our task is to explore and find the most 'covariate important' attributes provided in the data. To do this the code below will iterate across the sscores of all the features and sum the feature importance for all the covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "retired-concord",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Feature Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>631</td>\n",
       "      <td>cat16_B</td>\n",
       "      <td>0.222815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>cont5</td>\n",
       "      <td>0.068603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>cont1</td>\n",
       "      <td>0.051586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>cont6</td>\n",
       "      <td>0.049698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cont4</td>\n",
       "      <td>0.046975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>392</td>\n",
       "      <td>cat10_DR</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>388</td>\n",
       "      <td>cat10_DN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>387</td>\n",
       "      <td>cat10_DM</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>386</td>\n",
       "      <td>cat10_DL</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>321</td>\n",
       "      <td>cat10_AL</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>642 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index   Feature  Feature Score\n",
       "0      631   cat16_B       0.222815\n",
       "1        5     cont5       0.068603\n",
       "2        1     cont1       0.051586\n",
       "3        6     cont6       0.049698\n",
       "4        4     cont4       0.046975\n",
       "..     ...       ...            ...\n",
       "637    392  cat10_DR       0.000000\n",
       "638    388  cat10_DN       0.000000\n",
       "639    387  cat10_DM       0.000000\n",
       "640    386  cat10_DL       0.000000\n",
       "641    321  cat10_AL       0.000000\n",
       "\n",
       "[642 rows x 3 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the feature importance score.\n",
    "feature_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "swiss-shade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cat16', 0.22508575304504944)\n",
      "('cont5', 0.06860306610077353)\n",
      "('cont1', 0.05158577091656536)\n",
      "('cont6', 0.04969777937909494)\n",
      "('cont4', 0.04697476603494589)\n",
      "('cont2', 0.04658634056428416)\n",
      "('cont3', 0.0458471215180253)\n",
      "('cont8', 0.044787914199695134)\n",
      "('cont9', 0.04331071972551486)\n",
      "('cont10', 0.04256309103089788)\n",
      "('cont0', 0.042238636834348496)\n",
      "('cont7', 0.04177551739735028)\n",
      "('cat7', 0.028737288432072523)\n",
      "('cat10', 0.025988372012843087)\n",
      "('cat8', 0.024132414069392864)\n",
      "('cat1', 0.022723145594999074)\n",
      "('cat18', 0.021319939205017333)\n",
      "('cat2', 0.017420453228149894)\n",
      "('cat0', 0.016912787263963603)\n",
      "('cat15', 0.01569433708682284)\n",
      "('cat14', 0.011948463396334316)\n",
      "('cat4', 0.011683600445999273)\n",
      "('cat6', 0.010804064132678167)\n",
      "('cat9', 0.00930058889952817)\n",
      "('cat3', 0.00899891644705938)\n",
      "('cat11', 0.008875048394768284)\n",
      "('cat17', 0.0069880161011449)\n",
      "('cat5', 0.004632956866702823)\n",
      "('cat12', 0.002495243170243214)\n",
      "('cat13', 0.0022878885057348395)\n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary to find sum of feature importance scores for each full covariate\n",
    "covariate_importance = {}\n",
    "# Loop through all the features\n",
    "for index, row in feature_score_df.iterrows():\n",
    "    # Capture only covariate name\n",
    "    col = row['Feature'].split('_')[0]\n",
    "    # Capture feature importance score\n",
    "    score = row['Feature Score']\n",
    "    # Add the feature importance score with the name in dictionary and append.\n",
    "    if col in covariate_importance:\n",
    "        covariate_importance[col] += score\n",
    "    else:\n",
    "        covariate_importance[col] = score\n",
    "\n",
    "# Sort the dictionary according to the dictionary values.\n",
    "sorted_by_value = sorted(covariate_importance.items(),key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the dictionary in a presentable way.\n",
    "for covariate in sorted_by_value:\n",
    "    print(covariate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-grass",
   "metadata": {},
   "source": [
    "From the above results we can observe that the most important covariate is **cat16** which has a score of **22%** covariate importance.\n",
    "\n",
    "Additionally covariates **cont5, cont1** have a score of more than **5%** of covariate importance.\n",
    "\n",
    "Additionally covariates **cat9, cat3, cat11, cat17, cat5, cat12, cat13** have less than **1%** of covariate importance. This indicates that they might not be usefeull in predicting the target.\n",
    "\n",
    "\n",
    "**The above information can be useful in data collection, on the basis of gathering more or different data accordingly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-wrong",
   "metadata": {},
   "source": [
    "### [3.5] Tuning the hyperparameters of the candidate models\n",
    "\n",
    "We will apply a selective CV gridsearch on the 3 candidate models that we have chosen, with the goal of improving the perfomance measure (Accuracy). The training of the CV will be with reduced dimensioned data found from **[3.2]** .\n",
    "\n",
    "**NOTE:** \n",
    "Because of the technology available to us, it is too expensive to apply a complete gridsearch that assesses all the best options. For this reason we apply random values for the hyperparameters in hope of improving accuracy perfomance.\n",
    "\n",
    " * **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example hyperparameters to test.\n",
    "forest_parameters = {\n",
    "    'oob_score': [True],\n",
    "    'max_depth': [10, 15],\n",
    "    'max_features' : ['auto'],\n",
    "    'n_estimators': [100, 155]\n",
    "}\n",
    "# Create a based model\n",
    "base_forest = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "forest_search = GridSearchCV(estimator = base_forest,\n",
    "                           param_grid = forest_parameters, \n",
    "                           cv = 3, n_jobs = -1, verbose = 2 , random_state = 5059)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the grid search model to see the best params.\n",
    "forest_search.fit(reducedX_training, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing best parameter values from the CV gridsearch\n",
    "forest_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the best model obtained from the CV gridsearch\n",
    "# Model with smallest loss value.\n",
    "forest_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-patio",
   "metadata": {},
   "source": [
    "The above chunks were run on a different systems and the compilation of the best values are:\n",
    " * oob_score = True\n",
    " * max_depth = 15\n",
    " * max_features = 'auto'\n",
    " * n_estimators = 150\n",
    " \n",
    "We will now fit a random forest with these gridsearch results and obtain its perfomance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "yellow-medicine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 24s, sys: 10.8 s, total: 2min 35s\n",
      "Wall time: 2min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=15, n_estimators=150, oob_score=True,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fit best model and obtain results.\n",
    "# Instantiate model with 100 decision trees \n",
    "# oob_score needs to be true to consider out of bag sampling.\n",
    "Random_forest_model = RandomForestClassifier(n_estimators = 150,\n",
    "                                             random_state = 42,\n",
    "                                             oob_score=True,\n",
    "                                             max_depth = 15,\n",
    "                                             max_features = 'auto')\n",
    "\n",
    "Random_forest_model.fit(reducedX_training, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "driving-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "# we choose the 2nd column of results which is the prob predicted.\n",
    "y_predicted = Random_forest_model.predict_proba(reducedX_testing)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('CV-forest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-dispute",
   "metadata": {},
   "source": [
    "<font color=\"blue\">Running the above model with the reduced dimensions of 100% feature importance with 434 columns and best parameters from the grid search, we have achieved an accuracy score of **87.872%** which is **0.05% lower** than the Random Forest model with the full dimensions. <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-street",
   "metadata": {},
   "source": [
    " * **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example hyperparameters to test.\n",
    "logistic_parameters = {\n",
    "    'penalty': ['l2'],\n",
    "    'fit_intercept': [True, False],\n",
    "    'max_iter' : [250, 500, 2000]\n",
    "}\n",
    "# Create a based model\n",
    "base_logistic = LogisticRegression()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "logistic_search = GridSearchCV(estimator = base_logistic,\n",
    "                           param_grid = logistic_parameters, \n",
    "                           cv = 3, n_jobs = -1, verbose = 2 , random_state = 5059)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the grid search model to see the best params.\n",
    "logistic_search.fit(reducedX_training, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing best parameter values from the CV gridsearch\n",
    "logistic_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the best model obtained from the CV gridsearch\n",
    "# Model with smallest loss value.\n",
    "logistic_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-imperial",
   "metadata": {},
   "source": [
    "The above chunks were run on a different systems and a compilation of the best values are:\n",
    " * solver = saga\n",
    " * max_iter = 250\n",
    " * penalty = 'l2'\n",
    " * fit_intercept = False\n",
    " \n",
    "We will now fit a logistic regression model with these results and obtain its perfomance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "otherwise-guitar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 2.78 s, total: 1min 6s\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(fit_intercept=False, max_iter=250, random_state=123,\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fit best model and obtain results.\n",
    "# Constructing a logistic regression.\n",
    "log_reg = LogisticRegression(solver=\"saga\",\n",
    "                             max_iter= 250,\n",
    "                             random_state=123,\n",
    "                             penalty = 'l2',\n",
    "                             fit_intercept=False\n",
    "                            )\n",
    "# Fitting the logistic regression\n",
    "log_reg.fit(reducedX_training, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "simplified-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "# we choose the 2nd column of results which is the prob predicted.\n",
    "y_predicted = log_reg.predict_proba(reducedX_testing)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('CV-logistic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-cooking",
   "metadata": {},
   "source": [
    "<font color=\"blue\">Running the above model with the reduced dimensions of 100% feature importance with 434 columns and best parameters from the grid search, we have achieved an accuracy score of **87.715%** which is **0.02% lower** than the Logistic Regression model with the full dimensions. <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-casting",
   "metadata": {},
   "source": [
    " * **XGBoost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example hyperparameters to test.\n",
    "xgboost_parameters = {\n",
    "    'max_depth': [1,3,6],\n",
    "    'sampling_method': ['uniform','gradient_based'],\n",
    "    'learning_rate':[0.3,0.5,0.8],\n",
    "    'min_child_weight':[1,2]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "base_xgboost = XGBClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "xgboost_search = GridSearchCV(estimator = base_logistic,\n",
    "                           param_grid = logistic_parameters, \n",
    "                           cv = 3, n_jobs = -1, verbose = 2 ,scoring='roc_auc', random_state = 5059)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit the grid search model to see the best params.\n",
    "xgboost_search.fit(reducedX_training, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing best parameter values from the CV gridsearch\n",
    "xgboost_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the best model obtained from the CV gridsearch\n",
    "# Model with smallest loss value.\n",
    "xgboost_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-messaging",
   "metadata": {},
   "source": [
    "The above chunks were run on a different systems and the compilation of the best values are:\n",
    " * learning_rate = 0.3\n",
    " * max_depth = 6\n",
    " * min_child_weight = 2\n",
    " * sampling_method = unifrom\n",
    " \n",
    "We will now fit a XGBClassifier with these results and obtain its perfomance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "typical-estate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:35:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 18min 23s, sys: 15 s, total: 18min 38s\n",
      "Wall time: 12min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=2, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, sampling_method='uniform',\n",
       "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "# Fit best model and obtain results.\n",
    "# Constructing the XGBClassifier \n",
    "xgb_model = XGBClassifier(learning_rate = 0.3,\n",
    "                          random_state = 42,\n",
    "                          max_depth = 6,\n",
    "                          min_child_weight = 2,\n",
    "                          sampling_method = 'uniform'\n",
    "                         )\n",
    "# Fitting the XGBClassifier on full dataset.\n",
    "xgb_model.fit(reducedX_training, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "obvious-latter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predicting values using the test X matrix\n",
    "# we choose the 2nd column of results reducedX_testing is the prob predicted.\n",
    "y_predicted = xgb_model.predict_proba(reducedX_testing)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('CV-xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-malaysia",
   "metadata": {},
   "source": [
    "<font color=\"blue\">Running the above model with the reduced dimensions of 100% feature importance with 434 columns and best parameters from the grid search, we have achieved an accuracy score of **88.521%** which is **0.04% lower** than the XGB Classifier with the full dimensions. <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-salon",
   "metadata": {},
   "source": [
    "## [4] Best Model Achieved\n",
    "\n",
    "The best model we have managed to achieve is the **XGBoost Classifier** using the full dimensions of the data provided with an <font color=\"blue\"> **accuracy score of 88.56%** </font>. \n",
    "\n",
    "However, after reducing the dimensions we have managed to get very close accuracy score with the added benefit of decreasing the computational complexity. This being said it would be worth exploring the importance and influence of each covariate with our predicting target more in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-wholesale",
   "metadata": {},
   "source": [
    "## [5] Exploring Covariate Importance \n",
    "\n",
    "Even thought by decreasing the dimensions of the dataset we achieve a lower accuracy score. We manage to decrease the computational complexity in a large scale. This could be beneficial in terms of computational cost and in data collection cost. If it's expensice to collect all these dimensions of data, it might be worth reducing the dimensions in the data collection for a small cost of accuracy.\n",
    "We will explore this in more detail now, we will read in the data in again of its beginning state and create a function that wrangles the data in the appropriate structure to train our classifier.\n",
    "\n",
    "### Data Wrangle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sweet-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the training and testing set already provided.\n",
    "training_data = pd.read_csv(\"data/train.csv\")\n",
    "testing_data = pd.read_csv(\"data/test.csv\")\n",
    "submit_file = pd.read_csv(\"data/sample_submission.csv\", index_col='id')\n",
    "\n",
    "# Isolating the response value.\n",
    "trainY_response = training_data['target'].copy()\n",
    "\n",
    "# Dropping the values not needed in the datasets\n",
    "# From training = [targer, id]\n",
    "# From tesitng = [id]\n",
    "training_data.drop('target', axis = 1, inplace = True)\n",
    "testing_data.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thrown-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTION that one hot encodes the 2 datasets together.\n",
    "## Merged dataset will be send and it will be returned 1-Hot-Encoded\n",
    "def find_one_encoder(train, test):\n",
    "    ## MERGED DATA\n",
    "    # This will concatenate the test data rows below the train data\n",
    "    # The first 300K rows will be the train.\n",
    "    # The last 200K rows will be the testing.\n",
    "    merged_encoder = pd.concat([train, test])\n",
    "\n",
    "\n",
    "    # Using get_dummies() which is the same thing as 1-hot-encoder but ignores numerical values.\n",
    "    merged_encoder = pd.get_dummies(merged_encoder)\n",
    "    return(merged_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-flash",
   "metadata": {},
   "source": [
    "From the above results in [3.4] we obtained the whole covariate importance and produced a sorted table with them. Below we are creating filter sets, that will allow us to subsample our full data into smaller chunks. Each subsample chunk will hold the N most important covariates. These chunks will then be used in association with our best classifying model 'XGBoost Classifier' to predict our desired target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "graduate-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the top most important covariates in arrays.\n",
    "top5 = ['cat16','cont5', 'cont1', 'cont6', 'cont4']\n",
    "top10 = ['cat16','cont5', 'cont1', 'cont6', 'cont4', 'cont2', 'cont3','cont8', 'cont9', 'cont10']\n",
    "top15 = ['cat16','cont5', 'cont1', 'cont6', 'cont4', 'cont2', 'cont3','cont8', 'cont9', 'cont10', 'cont0', 'cont7',\n",
    "        'cat7','cat10', 'cat8' ] \n",
    "top20 = ['cat16','cont5', 'cont1', 'cont6', 'cont4', 'cont2', 'cont3','cont8', 'cont9', 'cont10', 'cont0', 'cont7',\n",
    "        'cat7','cat10', 'cat8', 'cat1','cat18','cat2','cat0','cat15'] \n",
    "top25 = ['cat16','cont5', 'cont1', 'cont6', 'cont4', 'cont2', 'cont3','cont8', 'cont9', 'cont10', 'cont0', 'cont7',\n",
    "        'cat7','cat10', 'cat8', 'cat1','cat18','cat2','cat0','cat15','cat14','cat4', 'cat6','cat9', 'cat3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-bargain",
   "metadata": {},
   "source": [
    "We will now subset our full data into the smaller chunks using the above filter sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hourly-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subseting data to top5 cov\n",
    "training_5 = training_data[top5].copy()\n",
    "testing_5 = testing_data[top5].copy()\n",
    "\n",
    "# Subseting data to top10 cov\n",
    "training_10 = training_data[top10].copy()\n",
    "testing_10 = testing_data[top10].copy()\n",
    "\n",
    "# Subseting data to top15 cov\n",
    "training_15 = training_data[top15].copy()\n",
    "testing_15 = testing_data[top15].copy()\n",
    "\n",
    "# Subseting data to top20 cov\n",
    "training_20 = training_data[top20].copy()\n",
    "testing_20 = testing_data[top20].copy()\n",
    "\n",
    "# Subseting to top25 cov\n",
    "training_25 = training_data[top25].copy()\n",
    "testing_25 = testing_data[top25].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-nation",
   "metadata": {},
   "source": [
    "###  Start trainign XGBoost with different datasets\n",
    "\n",
    "### For top 5 Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "gross-point",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.9/libexec/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 1min 6s, sys: 851 ms, total: 1min 7s\n",
      "Wall time: 25.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# First 300K rows is our training set.\n",
    "top5_train_X_data = find_one_encoder(training_5,testing_5).iloc[:300000,:]\n",
    "# Last 200K rows is our testing set.\n",
    "top5_test_X_data = find_one_encoder(training_5,testing_5).iloc[300000:,:]\n",
    " \n",
    "# Constructing the XGBClassifier \n",
    "xgb_model = XGBClassifier(random_state = 42)\n",
    "# Fitting the XGBClassifier on full dataset.\n",
    "xgb_model.fit(top5_train_X_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "y_predicted = xgb_model.predict_proba(top5_test_X_data)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('top5-xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-diamond",
   "metadata": {},
   "source": [
    "**Accuracy Score from Kaggle = 84.741%**\n",
    "### For top 10 Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "radical-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 2min 5s, sys: 1.41 s, total: 2min 6s\n",
      "Wall time: 47.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# First 300K rows is our training set.\n",
    "top10_train_X_data = find_one_encoder(training_10.copy(),testing_10.copy()).iloc[:300000,:]\n",
    "# Last 200K rows is our testing set.\n",
    "top10_test_X_data = find_one_encoder(training_10.copy(),testing_10.copy()).iloc[300000:,:]\n",
    " \n",
    "# Constructing the XGBClassifier \n",
    "xgb_model = XGBClassifier(random_state = 42)\n",
    "# Fitting the XGBClassifier on full dataset.\n",
    "xgb_model.fit(top10_train_X_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "y_predicted = xgb_model.predict_proba(top10_test_X_data)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('top10-xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-format",
   "metadata": {},
   "source": [
    "**Accuracy Score from Kaggle = 85.562%**\n",
    "### For top 15 Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "female-dispatch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 17min 33s, sys: 10.4 s, total: 17min 43s\n",
      "Wall time: 6min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# First 300K rows is our training set.\n",
    "top15_train_X_data = find_one_encoder(training_15.copy(),testing_15.copy()).iloc[:300000,:]\n",
    "# Last 200K rows is our testing set.\n",
    "top15_test_X_data = find_one_encoder(training_15.copy(),testing_15.copy()).iloc[300000:,:]\n",
    " \n",
    "# Constructing the XGBClassifier \n",
    "xgb_model = XGBClassifier(random_state = 42)\n",
    "# Fitting the XGBClassifier on full dataset.\n",
    "xgb_model.fit(top15_train_X_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "y_predicted = xgb_model.predict_proba(top15_test_X_data)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('top15-xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-theme",
   "metadata": {},
   "source": [
    "**Accuracy Score from Kaggle = 86.683%**\n",
    "### For top 20 Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "equipped-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:37:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 20min 11s, sys: 6.54 s, total: 20min 18s\n",
      "Wall time: 6min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# First 300K rows is our training set.\n",
    "top20_train_X_data = find_one_encoder(training_20.copy(),testing_20.copy()).iloc[:300000,:]\n",
    "# Last 200K rows is our testing set.\n",
    "top20_test_X_data = find_one_encoder(training_20.copy(),testing_20.copy()).iloc[300000:,:]\n",
    " \n",
    "# Constructing the XGBClassifier \n",
    "xgb_model = XGBClassifier(random_state = 42)\n",
    "# Fitting the XGBClassifier on full dataset.\n",
    "xgb_model.fit(top20_train_X_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "y_predicted = xgb_model.predict_proba(top20_test_X_data)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('top20-xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-return",
   "metadata": {},
   "source": [
    "**Accuracy Score from Kaggle = 88.104%**\n",
    "### For top 25 Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "thrown-overall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:43:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 23min 3s, sys: 8.95 s, total: 23min 12s\n",
      "Wall time: 6min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# First 300K rows is our training set.\n",
    "top25_train_X_data = find_one_encoder(training_25.copy(),testing_25.copy()).iloc[:300000,:]\n",
    "# Last 200K rows is our testing set.\n",
    "top25_test_X_data = find_one_encoder(training_25.copy(),testing_25.copy()).iloc[300000:,:]\n",
    " \n",
    "# Constructing the XGBClassifier \n",
    "xgb_model = XGBClassifier(random_state = 42)\n",
    "# Fitting the XGBClassifier on full dataset.\n",
    "xgb_model.fit(top25_train_X_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "y_predicted = xgb_model.predict_proba(top25_test_X_data)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('top25-xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-understanding",
   "metadata": {},
   "source": [
    "**Accuracy Score from Kaggle = 88.357%**\n",
    "### For top 30 Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Constructing the XGBClassifier \n",
    "xgb_model = XGBClassifier(random_state = 42)\n",
    "# Fitting the XGBClassifier on full dataset.\n",
    "xgb_model.fit(full_train_X_data, trainY_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting values using the test X matrix\n",
    "y_predicted = xgb_model.predict_proba(full_test_X_data)[:,1]\n",
    "# Calling function to write the csv file\n",
    "submit_file['target'] = y_predicted\n",
    "submit_file.to_csv('top30-xgboost.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-passenger",
   "metadata": {},
   "source": [
    "**Accuracy Score from Kaggle = 88.564%**\n",
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "synthetic-terror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Putting results in data frame to plot the trade-off.\n",
    "data = {'Number Of Covariates':  [5, 10, 15, 20, 25, 30],\n",
    "        'Accuracy Score': [84.741, 85.562, 86.683, 88.104, 88.357,88.564]\n",
    "        }\n",
    "\n",
    "trade_off = pd.DataFrame (data, columns = ['Number Of Covariates','Accuracy Score'])\n",
    "\n",
    "# Plotting data\n",
    "trade_off_plot = sns.lineplot(data=trade_off, x=\"Number Of Covariates\", y=\"Accuracy Score\")\n",
    "trade_off_plot.set_title(\"Number covariate-accuracy tradeoff\")\n",
    "# Saving plot (IF you want to save, uncomment the next two lines.)\n",
    "# figure_save = trade_off_plot.get_figure()\n",
    "# figure_save.savefig(\"trade-off.png\")\n",
    "\n",
    "# Previewing plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-victory",
   "metadata": {},
   "source": [
    "From the above plot, we can conclude that every single covariate has information to offer that allows us to predict with higher accuracy. However the final 10 covariates bring only an extra of 0.4% accuracy. If the following covariates are very expensive to collect:\n",
    " \n",
    " 1. cat14\n",
    " 2. cat4\n",
    " 3. cat6\n",
    " 4. cat9\n",
    " 5. cat3\n",
    " 6. cat11\n",
    " 7. cat17\n",
    " 8. cat5\n",
    " 9. cat12\n",
    " 10. cat13\n",
    " \n",
    "From the result table obtained in [3.4] we see the last 7 important covariates [cat9 - cat13] do not constribute even 1% in our prediction importance. With all these being said, by ommiting these dimensios from the data collection could benefit in the financial cost of the company.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
