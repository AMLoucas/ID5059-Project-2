## Python and R Hybrid

How can we use both?
The `reticulate` library (2020) enables us to use both Python and R functions and coding in one place, a R Markdown file.

More information on the library specifications and functionalities can be found [here](https://rstudio.github.io/reticulate/)

Source all functions from the python script `Imputation_Simulation_Study()`

``` {r, setup, echo = FALSE, message = FALSE, warning=FALSE}

library(reticulate) # Allowing to use Python code in RMarkwdown.

source_python("Imputation_Simulation_Study.py") # Importing python functions used in final simulation.

```

All other requirements for this document:

``` {r echo = FALSE, message = FALSE, warning=FALSE}

# For
library(dplyr)         # Allows to use '%>%' and handy functions that help with data wrnagling.
library(tidyr)         # Allows to use method 'gather()'

# For Analysis
library(missForest)    # For multivariate methods imputers
library(mice)          # For multivariate methods imputers

# For Performance Metrics
library(caret)         # For confusion matrix
library(matrixStats)   # For calculating sd of multiple columns

```

---

## References

**References for this document**

[1 : Flexible Imputation of Missing Data - Second Edition - Stef Van Buuren](https://stefvanbuuren.name/fimd/)

[2 : Inference and Missing Data - Rubin](https://www.jstor.org/stable/2335739?seq=1)

[3 : MICE: Multivariate Imputation by Chained Equations in R](https://www.researchgate.net/publication/44203418_MICE_Multivariate_Imputation_by_Chained_Equations_in_R)

[4 : MissForestâ€”non-parametric missing value imputation for mixed-type data](https://academic.oup.com/bioinformatics/article/28/1/112/219101)

[5 : Imputing Missing Data with R MICE Package](https://datascienceplus.com/imputing-missing-data-with-r-mice-package/)

[6 : MissForest : Non-Parametric imputation technique](https://arxiv.org/pdf/1105.0828.pdf)

## Imputation

> Imputation is the act of converting an incomplete sample into a complete sample. [1]

The idea behind this analysis is to construct a simulation study. This traditionally can be split into three key steps:

1. Simulation Step
2. Application of Methods
3. Assessing Performance of Methods

----

### 1. **Removing Data At Random** [Simulation Step]

#### Types of Missing Data

Rubin [2] classified missing data problems into three categories, which are all driven by the so-called **response mechanism**.
This mechanism can be modelled, as long as an assumption is made as to which response mechanism drove the data to be missing in the first place. The categories are **Missing Completely at Random** (MCAR), **Missing at Random** (MAR), **Missing not at Random** (MNAR). In short, these can be described as;

1. **MCAR** : when the probability of data missing is the same across the entire datset.
2. **MAR** : when the probability of data missing is the same across groups within the dataset.
3. **MNAR** : when the probability of data missing depends on an unknown factor.

The current **methodologies** in the literature rely on a **key assumption** choice of either three categories. Hence, certain methods will be more suitable than others depending on the data and whether the assumption is met or not will underpin the validity of statistical inferences.

Another important distinction to make it between **Univariate** and **Multivariate Missing Data**. These are defined as the problem where only one feature is missing and the problem where more than one feature is missing respectively. In our simulation function we will have freedom to choose every time which case to be in.

#### In Practice

For this special case, the simulation step is slightly unusual. Normally one would sample from a known distribution, however in this instance the sampling happens as way to **identify the location of the values which will be dropped**, i.e. become NaN.

1. For the **MCAR** Case:

  Mathematically, let $n$ be the total number of observations (rows) in the dataset and $m$ be the total number of features (columns) in the dataset. Hence, let $U_1$ and $U_2$ be two sets $U_1 \in {1,...,n} \text{  and } U_2 \in {1,...,m}$. By sampling with replacement k times from these two sets independently, such that any outcome is equally likely, the resulting ordered outcomes indicate the indexing of the element which will be dropped. These indexes can be viewed as the tuples $(u_1{_i}, u_2{_i}) \text{  for  } i \in {1,...,k}$.
  
2. For the **MAR** Case:

  *Maybe to do??? could add an input to the simulation function() like data_type where it can take values "MCAR" or "MAR"*
  *Could be interesting to see if MICE methods perform better when there is actually an underlying relationship which drives the presence of the missing data, i.e. their assumption is met*

##### Function to Remove Data (in Python)

``` {python eval = FALSE, message = FALSE, warning=FALSE}

def remove_random_values(true_df, columns, percentage):
    """
    Funtion the will remove values from the selected columns at random,
    then replace the removed values with np.nan which is NaN.

    PSEUDOCODE:

    1. Random sample row indexes (with replacement)
    2. Random sample column labels (with replacement)
    3. Extract random entry using 1. and 2. and replace with np.nan
    4. Repeat (1-3) until total proportion of data has been extracted

    :param df: pandas DataFrame which is the full data
    :param columns: list of columns to 'drop' values from. Note: must be string name of columns
    :param percentage: float input such as 0.20 (i.e. 20%)
    :return: pandas DataFrame of the same shape as the original with NaN entries
    """

    start = time.time()
    
    # Set up: Focus on subset of data dependent on columns,
    #         hence extract information about subset and number of values to drop
    subset = true_df[columns].copy()
    nrow, ncol = true_df[columns].shape
    n_samples = int(percentage*nrow)

    # 1. Pick out a vector of random samples (row indexes)
    row_indexes = np.arange(0, nrow, 1).tolist()

    # 2. Sample with replacement from the list of possible indexes
    #    note, `choices` is used to sample with replacement
    sampled_row_indexes = random.choices(row_indexes, k = n_samples)
    sampled_columns = random.choices(columns, k = n_samples)

    # 3. Extract entry and replace accordingly 
    for i in range(0, n_samples):
        if sampled_columns[i][0:3] == 'cat':
            subset.loc[sampled_row_indexes[i], sampled_columns[i]] = 'nan'
        else:
            subset.loc[sampled_row_indexes[i], sampled_columns[i]] = -1
            # this is the convention for a number of sklearn packages

    # Notes: having it as a loop ensures we are not holding a massive dataframe in memory so its a lot faster.
    # Notes: must use 'nan' and numerical as np.nan would not be updated in step 4. otherwise.

    # 4. Update data frame with new NaN values
    true_df.update(subset)
    true_df = true_df.replace('nan', np.nan)
    true_df = true_df.replace(-1, np.nan)

    end = time.time()
    print("Random Sampling Complete - Time Elapsed : ", end - start)

    return(true_df)

```

----

### 2. **Choosing the Imputation Methods** [Methods Step]

#### Types of Models

The simplest and most common solutions for missing data problems are 

* *likewise deletion*, which is simply removing the rows with missing elements from the dataset,
* *mean* or *median imputation*, which is substituting the missing feature with the sample mean or median over all observed values in that same feature column.
* *regression imputation*, which is about creating a regression model, hence incorporating the effects of other features, and using the model to predict the missing data.
* *stochastic regression imputation*, which is similar as above but incorporates variability of the predictions.
* *and more...*

In general however, these fall into two broad categories: **Univariate** and **Multivariate Imputation Methods**.
This simply indicates whether the method takes into account all the data features to determine the missing data (multivariate) or only the column the missing data belongs to (univariate). 

There is a key increase in **computational effort when using multivariate methods**, however these often perform better as they take into consideration the relationship between all the data when making a choice. This implies that often **correlation structures** across features are kept intact, compared to univariate methods which completely disregard them. 

For the sake of this analysis and simulation study, we will explore both in some level of detail.

Due by **multivariate nature of the sampling** *(i.e. dropping data from more than one feature)*, there are three main strategies to consider:

1. **Monotone data imputation**. Imputations are created by a sequence of univariate methods;
2. **Joint modeling**. Imputations are drawn from a multivariate model fitted to the data;
3. **Fully conditional specification**, also known as multivariate imputation by chained equations. A multivariate model is implicitly specified by a *set of conditional univariate models*. Imputations are created by drawing from iterated conditional models.

    **Note** : 1. is better suited for monotone missing data patterns and 2. and 3. are suitable for general missing data patterns.

#### **Univariate Methods** to consider:

Univariate imputation methods chosen fall into some of the standard ideas which were mentioned before.

* `Median SimpleImputer`, this is a standard sklearn imputer which takes the column feature and uses the median value as the imputed value all missing values. *Note*: this only copes with numerical features.

* `MostFrequent SimpleImputer`, this is another standard sklearn imputer which takes the column feature and uses the most frequent category as the imputed value for all missing values. *Note*: this only copes with categorical features.

##### Function to Run Univariate Imputation Methods

``` {python eval = FALSE, message = FALSE, warning=FALSE}

def univariate_imputation_method(nans_df):
    """
    Function which runs through our chosen three methods: Median Imputation, and Most Frequent Imputation
    
    Code from https://dzone.com/articles/imputing-missing-data-using-sklearn-simpleimputer helped remove errors
    when imputing isolated columns alone. Was getting error 'expected 2D array and was provided with 1D array'

    :param nans_df: pandas DataFrame which has missing data - subset on the columns to impute only
    :return: the imputed dataset
    """
    
    # Start time
    start = time.time()

    # Dataset that will be imputed and returned to main
    imputed_data = nans_df.copy()

    # Looping through each column that has to be imputed.
    # Doing this tactic to capture name of column
    for column in imputed_data:
        # Checking if the column is categorical data type and using most frequent tactic
        if column[0:3] == 'cat':
            imputer_tactic = SimpleImputer(strategy = "most_frequent")
        # Checking if the column is numerical data type and using mean tactic
        else:
            imputer_tactic = SimpleImputer(strategy = "mean")
        
        # Imputing the specific column with the appropriate specific tactic
        imputed_data[column] = imputer_tactic.fit_transform(imputed_data[column].values.reshape(-1,1))[:,0]


    end = time.time()

    print("Most Frequent Imputation Complete - Time Elapsed :", end - start)

    return imputed_data

```

#### **Multivariate Methods** to consider:

For this analysis we focused on two key approaches.

* `MICE`, Multivariate Imputation by Chained Equations. More info can be found in the [docs](https://www.rdocumentation.org/packages/mice/versions/3.13.0/topics/mice)

* `MissForest` Imputer, this is a Nonparametric Missing Value Imputation using **Random Forest**. More info can be found in the [docs](https://cran.r-project.org/web/packages/missForest/missForest.pdf)
   
    **Note** : both cope with mixed data well.

``` {python message = FALSE, eval = TRUE, echo = FALSE, warning=FALSE}

## FUNCTION
#  Function that reads the true data frame we want to apply imputation research on.
## INPUTS
#  full_path: string input representing path to the full training data
## OUTPUT
#  data frame containing all true values.
def read_true_values(full_path):
  true_df = pd.read_csv(full_path)
  return(true_df)

```

##### MICE Fitting and Function

One of the key assumptions of MICE is that the **response mechanism is MAR**. Hence, that there is value in imputing values using a combination of all other features of the data. Which features are used as the *predictive variables* for the *imputed values* is shown in the output of PredictiveMatrix.

> For datasets containing hundreds or thousands of variables, using all predictors may not be feasible (because of multicollinearity and computational problems) to include all these variables. It is also not necessary. [1]

The **recommended steps for large datasets**, in short, are:

1. Include all features that appear in the model that will be applied to the data after imputation, including the outcome.
2. Include any feature which is known to be likely to be a driver for the missing data.
3. Include any feature which seems to explain a lot of the variance of the data.

**Note** : The mice package contains several tools that aid in automatic predictor selection. The `quickpred()` function is a quick way to define the predictor matrix using the strategy outlined above. [3] ...  The mice() function detects multicollinearity, and solves the problem by removing one or more predictors for the model. Each removal is noted in the loggedEvents element of the mids object.

Lastly, there is a wide range of choices in terms of the `methods` to deploy for this multivarite fitting.
More information can be found at [1] - *Section 6.3 Model form and predictors*.

The **default methods used** are:

* for unordered factor variables with more than two levels : `polyreg` - Bayesian Polytomous Regression
* for continuous variables : `ppm` - Predictive Mean Matching

``` {r message = FALSE, eval = TRUE, warning = FALSE}

### FUNCTION
# Function that imputes missing values using the 'mice' machine learning algorithm.
## INPUT
# nans_df: data frame containing all NA values.
# columns: which columns to be considered in the imputation prediction.
## OUTPUT
# (data frame's) that data was imputed with mice. According to the variable m is the number of data frames.
impute_using_mice <- function(nans_df, columns) {
  
  start_time <- Sys.time()

  imp_df_mice <- mice(nans_df[columns], m = 3, maxit = 5) #, seed = 5059)
  
  end_time <- Sys.time()
  print(paste("Time taken to impute using MICE is: ", (end_time - start_time)))
  
  return(imp_df_mice)
  
  }
```

**Notes**;

* Interestingly, when running the MICE imputer on the categorical data only, this error comes up:

  `# Error in edit.setup(data, setup, ...) : mice detected constant and/or collinear variables. No predictors were left after their removal`

  Which indicates to me that all categorical variables may be drawn from the exact same sampling and that the labelling has no true meaning.
  Hence, for some meaningful predictions I kept a continuous feature `cont0` as the main predictor for both categorical features to impute.


##### MissForest Fitting and Function

The machine learning imputation method 'MissForest' follows an iterative lifecycle and is **based on the 'Random Forest' predictive model**. The specific algorithm does not fill missing cells with constants but with predictions. It predicts the missing values using a 'Random Forest' classification or regression model and the final predicted cell value is the **average or the majority of predictions obtained**.

 * Average used when we filling numerical data types.
 * Majority is used when we filling categorical data types.

The steps and process of a **MissForest lifecycle**:

 1. Fill missing values using the mode ('most frequent') or mean of the column.
 2. Train a Random Forest model using a complete data set.
 3. Predict the missing values using the model trained above.
 4. Re-fit Random Forest with dataset filled with the previous predicts values rather than mean/mode
 5. Predict missing values again.
 6. The above process is done in an iterative fashion and stops according to the stopping technique used
 
The MissForest imputation technique has outperformed other methods multiple times in different researches. Using the Random Forest models allows to take the advantage of out of **bag sample evaluating technique**, which does not need a test set. These techniques help and allow the algorithm to **perform very well when the data follows a complex non linear relation** within it. However when it follows a linear relation, other models are preferred which are created to capture such relations. Another benefit of using the MissForest it that it considers the randomness of data and is computationally efficient, which allows to deal with data of high dimensions. In addition to, the imputation method can deal with categorical and numerical data types. When predicting a categorical data type,  classification tree models are used in the forest. On the other hand when predicting a numerical data type, regression tree models are used in the forest.

The main benefit of using a MissForest model is that the algorithm is non-parametric. It does not assume any assumptions on the structural aspects of the data. This has no constraint of when a MissForest is appropriate, as it can deal with structured data and unstructured data. More on the MissForest algorithm can be found on reference [6] 


We can apply the MissForest imputation method using R package 'missForest' provided for us.

``` {r message = FALSE, eval = TRUE, warning = FALSE}

### FUNCTION
# Function that imputes missing values using the 'missForest' machine learning algorithm.
## INPUT
# nans_df: data frame containing all NA values.
# columns: which columns to be considered in the imputation prediction.
## OUTPUT
# (data frame) that data was imputed with missForest
impute_using_missForest <- function(nans_df, columns) {
  
  start_time <- Sys.time()
  
  imp_df_forest <- missForest(nans_df[columns])$ximp
  
  end_time <- Sys.time()
  print(paste("Time taken to impute using missForest is: ", (end_time - start_time)))
  
  return(imp_df_forest)
  
}

```

**Notes**;

* By construction of algorithm cannot run on categorical variables with more than 53 factors: drop cat10 and cat8 and cat5. There are different techniques to deal with this phenomeno. We can apply a One v One Strategy but this would make the model more computationl expensive. Since we have many multiple variables, we choose to not include them in the Random Forest and use the rest. 

----

### 3. **Evaluating Performance of the Imputation Methods** [Evaluation Step]:

#### Types of Adequate Performance Metrics:

##### For Continuous Features:

* **Normalized Root Mean Squared Error (NRMSE)**:

  $\sqrt{mean((X_{true} âˆ’ X_{imp})^2)/var(X_{true})}$

  where
    $X_{true}$ the complete data matrix and $X_{imp}$ the imputed data matrix
    
  *For good performance we expect values to be close to zero.*
    
* **Difference between true value and imputed value**

  $D = x_{true} - x_{imp}$
  
  where
    $x_{true}$ the true value from the data matrix and $x_{imp}$ the imputed value from the data matrix
    
  *For good performance we expect values to be concentrated about zero.*
    
* **Percentage difference between true value and imputed value**

  $PD = 100 * |(x_{true} - x_{imp})/x_{true}|$
  
  where
    $x_{true}$ the true value from the data matrix and $x_{imp}$ the imputed value from the data matrix
  
  *For good performance we expect values to be concentrated close to zero.*

##### For Discrete Features:

* **Confusion Matrix** : count the number of *True Positives*, *False Negatives*, *False Positives* and *True Negatives* and store them in a matrix to assess performance of predictor.

    *Good performance is indicated by higher counts in the diagonal of the matrix.*

* **Accuracy** : sum the counts in the *diagonal* of the confusion matrix (True Positive and True Negative) and divide by the sum of all entries in the confusion matrix.

    *Good performance leads to a value close to 1 and bad performance to a value around 0.*

* **Proportion of falsely classified** (PFC) : sum the counts in the *off diagonal* of the confusion matrix (False Negative and False Positive) and divide by the sum of all entries in the confusion matrix.

    *Good performance leads to a value close to 0 and bad performance to a value around 1.*

##### Functions to Evaluate Performance Metrics (Python)

``` {python message = FALSE, eval = FALSE, warning=FALSE}

def performance_results_py(true_df, imp_df, nans_df, columns):
    """
    Function to extract true values and imputed values and compute performance metrics.
    :param true_df: pandas DataFrame containing true values
    :param imp_df: pandas DataFrame containing imputed values
    :param nans_df: pandas DataFrame containing nans
    :param columns: columns containing imputed values
    :return: list of results such that indexing returns results for each column (in columns) respectively
             for each column you then have the output from performance_metrics() which depends on the data type
    """

    results = []
    for column in columns:

        # a. Extract boolean vector (True/False) to identify Imputed True Data Vectors
        # Expect different values in cell, because comparing true with the NaN removed.
        boolean_values = (true_df != nans_df)[column].to_numpy().tolist()
       
        # c. Extract Imputed Data Vectors
        # Using Boolean Pointer list from above, extract true values
        true_values = true_df[column][boolean_values]
        # Using Boolean Pointer list from above, extract imputed values
        imputed_values = imp_df[column][boolean_values].to_numpy().tolist()

        # d. Evaluate performance metrics
        # Call function the two columns and obtain metrics. 
        results.append(performance_metrics(imputed_values, true_values))

    return(results)

def performance_metrics(imputed_values, true_values):
    """
    Function to calculate all performance metrics of interest for each list of imputed vs true values.

    :param imputed_values: list of imputed values
    :param true_values: list of true values
    :return: if categorical - measures of accuracy and the confusion matrix
             if numerical - measures of raw difference and percentage difference between
                            imputed value and true value
             
    Note: each list for now is specific to each column, as it supports univariate imputations.
    Note: depending the on the methods used the columns are independent of each other,
          e.g. the median imputation does not use any other column at all -
          implying that we can assess performance independently of one another.
    """

    # If Categorical Feature
    if isinstance(imputed_values[0], str):

        # Confusion Matrix
        conf_matrix = metrics.confusion_matrix(true_values, imputed_values)

        # Accuracy
        accuracy = metrics.accuracy_score(true_values, imputed_values)

        # Precision
        # precision = metrics.precision_score(true_values, imputed_values)
        # todo: fix - precision not working as it requires a 'positive' label, it could work better if I encoded the categories

        return(conf_matrix, accuracy)

    # If Numerical Feature
    elif isinstance(imputed_values[0], float):

        # 1. The difference between the imputed value and truth
        D = np.array(imputed_values) - np.array(true_values)
        sample_mean = np.mean(D)
        sample_sd = np.sqrt(np.var(D))

        #    Plot
        # ci = norm(*norm.fit(D)).interval(0.95)
        # height, bins, patches = plt.hist(D, alpha = 0.3)
        # plt.fill_betweenx([0, height.max()], ci[0], ci[1], color = 'g', edgecolor = 'white', alpha = 0.1)
        
        # 2. The percentage difference between the imputed value and truth
        PD = 100 * abs((np.array(imputed_values) - np.array(true_values))/np.array(true_values))

        return(D, PD, sample_mean, sample_sd)

    else:

        return(None)
        
        
```

##### Function to Evaluate Performance Metrics (R)

``` {r message = FALSE, warning=FALSE}

## FUNCTION
#  Function to extract true values and imputed values and compute performance metrics for mice.
## INPUTS
#  true_df: data.frame containing true values
#  imp_df: output directly from methods `mice()` 
#  columns: vector input containing strings representing column names which contain imputed values
## OUTPUT
#  list containing:
#    for categorical - measures of accuracy and the confusion matrix
#    for numerical - measures of raw difference and percentage difference between
#                   imputed value and true value
performance_results_mice <- function(true_df, imp_df, columns) {
  
  start_time <- Sys.time()
  
  # number_iterations : Number of iterations mice has done.
  # Each iteration computes imputation valus
  # We will find results from all values and get their average values.
  number_iterations <- ncol(imp_df$imp[[columns[1]]])
  
  # empty storages to fill with the metrics. [ALL metrics and can be indexed with $]
  all_results <- list()

  # For each column we imputed values we will found a metric.
  for (column in columns) {
  
    # extract true values to compare with imputed.
    imp_rows <- row.names(imp_df$imp[[column]])
    truth <- data.frame(true_df[[column]])[imp_rows, ]
    
    accuracies <- c()
    # Check if it is continuous or categorical values to apply appropriate computations.
    if (startsWith(column, "cat")) {
      
      for (i in 1:number_iterations) {

        # extract imputed values for each iteration of mice.
        pred <- imp_df$imp[[column]][[i]]

        analysis_table <- table(pred, truth)
        res <- confusionMatrix(analysis_table)
        accuracies <- c(accuracies, res$overall[1])
        # - - - 
      }
      
    # store results for each column.
    all_results$conf_matrix[[column]] <- res$table
    all_results$accuracy[[column]] <- mean(accuracies)
    
    } else {
      
    # Subtracting the true - pred to get the difference from two vectors.
    # Where equal we expect 0. If imputed overestimating +, IF imputed underestimating -.
    # Result will be 3 columns, difference for each imputation run.
    all_results$D[[column]] <- truth - imp_df$imp[[column]][,]
    all_results$PD[[column]] <- 100 * abs((truth - imp_df$imp[[column]][,]) / truth)
    all_results$mean[[column]] <- colMeans(all_results$D[[column]])
    all_results$sd[[column]] <- colVars(as.matrix(all_results$D[[column]]))

    }
  }
  
  end_time <- Sys.time()
  print(paste("Time taken to compute MICE metrics is: ", (end_time - start_time)))
  # Returning list that holds all values tha can be indexed with '$'
  return(all_results)
  
}

# - - - - 

## FUNCTION
#  Function to extract true values and imputed values and compute performance metrics for missForest.
## INPUTS
#  true_df: data.frame containing true values
#  imp_df: output directly from methods `missForest().ximp`
#  nans_df: data.frame which we randomly replaced true values with NA's
#  columns: vector input containing strings representing column names which contain imputed values
## OUTPUT
#  list containing:
#    for categorical - measures of accuracy and the confusion matrix
#    for numerical - measures of raw difference and percentage difference between
performance_results_missForest <- function(true_df, imp_df, nans_df, columns) {
  
  start_time <- Sys.time()

  # empty storages to fill with the metrics. [ALL metrics and can be indexed with $]
  all_results <- list()

  # For each column we imputed values we will found a metric.
  for (column in columns) {
    
    # extract true values to compare with imputed.
    rows_imputed <- nans_df %>%
      mutate(row_names = row.names(nans_df)) # Creating a row_id in data frame.
    
    # Keeps rows that have NA values in column only.
    rows_imputed <- rows_imputed[is.na(rows_imputed[[column]]), ] 
    
    # Extract the cells for true and imputed values to compare between.
    truth <- data.frame(true_df[[column]])[rows_imputed[["row_names"]], ]
    pred <- data.frame(imp_df[[column]])[rows_imputed[["row_names"]], ]
    
    accuracies <- c()
    # Check if it is continuous or categorical values to apply appropriate computations.
    if (startsWith(column, "cat")) {

      analysis_table <- table(pred, truth)
      res <- confusionMatrix(analysis_table)
      accuracies <- c(accuracies, res$overall[1])
      # - - - 
      
      # store results for each column.
      all_results$conf_matrix[[column]] <- res$table
      all_results$accuracy[[column]] <- mean(accuracies)
      
    } else {
      
    # Subtracting the true - pred to get the difference from two vectors.
    # Where equal we expect 0. If imputed overestimating +, IF imputed underestimating -.
    # Result will be 3 columns, difference for each imputation run.
    all_results$D[[column]] <- truth - pred
    all_results$PD[[column]] <- 100 * abs((truth - pred) / truth)
    all_results$mean[[column]] <- mean(all_results$D[[column]])
    all_results$sd[[column]] <- sd(as.matrix(all_results$D[[column]]))
    
    }
  }
  
  end_time <- Sys.time()
  print(paste("Time taken to compute missForest metrics is: ", (end_time - start_time)))

  return(all_results)
  
  }

```

----

#### ASIDE: need to include **data wrangling functions** to transfer data from python to R

``` {r message = FALSE, eval = TRUE, echo = FALSE, warning = FALSE}

## FUNCTION
#  Function wrangles the data in appropriate structure for machine learning imputations.
## INPUTS
#  nans_df: data.frame containing random NA's values
## OUTPUT
#  NA data frames that are in appropriate state.
wrangle_data_for_na <- function(nans_df) {
  
  # note: there is a slight conversion issue between NaN and NA, hence we can explicitly use
  nans_df[nans_df == 'NA'] = NA
  
  # Converting the data into R data frames.
  nans_df <- as.data.frame(nans_df)
  
  # note: all character types must be changed to factors
  nans_df <- nans_df %>%
    mutate_if(is.character, as.factor) # if col is char -> convert to factor
  
  nans_df <- nans_df %>%
  mutate(cont0 = unlist(cont0), # unlist all continouus variables to be imputed.
    cont1 = unlist(cont1),
    cont2 = unlist(cont2),
    cont3 = unlist(cont3),
    cont4 = unlist(cont4),
    cont5 = unlist(cont5),
    cont6 = unlist(cont6),
    cont7 = unlist(cont7),
    cont8 = unlist(cont8),
    cont9 = unlist(cont9),
    cont10 = unlist(cont10)
    )
  
  return(nans_df)
}

# - - - - 

## FUNCTION
#  Function wrangles the data in appropriate structure for machine learning imputations.
## INPUTS
#  true_df: data.frame containing true values.
## OUTPUT
#  original data frames that are in appropriate state.
wrangle_data_for_original <- function(true_df) {
  
  # Converting the data into R data frames.
  true_df <- as.data.frame(true_df)
  
  # note: all character types must be changed to factors
  true_df <- true_df %>%
    mutate_if(is.character, as.factor) # if col is char -> convert to factor
  
  return(true_df)
}

```


``` {r echo = FALSE, eval = TRUE, warning = FALSE}
### FUNCTION
# Its a function that will print the result metrics obtained for each simulation run
# Its used to make code more compact and reproducible. Avoiding duplicate code
## INPUTS
# simulation: String indicating which simulation run the results are
# columns: List holding the value of which columns were used.
# simple: List holding the results involving Simple Imputer
# mice: List holding the results involving Mice Imputer
# forest: List holding the results involving the MissForest Imputer
print_metrics_obtained <- function(simulation, columns, simple, mice, forest) {
  
  cat("For Simulation Run", simulation," the scores are: ", '\n',
    "The mean difference for simple imputer", columns[[1]] ," :", simple[[1]]$mean," ", columns[[2]] ," :", simple[[2]]$mean, '\n',
    "The mean difference for mice ", columns[[1]] ," :", mice$mean$cont0, " ", columns[[2]] ," :", mice$mean$cont1, '\n',
    "The mean difference for missForest ", columns[[1]] ,":", forest$mean[[1]], " ", columns[[2]] ," :", forest$mean[[2]], '\n',
    "The sd difference for simple imputer ", columns[[1]] ,":", simple[[1]]$sd, " ", columns[[2]] ," :", simple[[2]]$sd, '\n',
    "The sd difference for mice ", columns[[1]] ," :", mice$sd$cont0, " ", columns[[2]] ," :", mice$sd$cont1, '\n',
    "The sd difference for missForest ", columns[[1]] ," :", forest$sd[[1]], " ", columns[[2]] ," :", forest$sd[[2]] , '\n')
}

```
***

### 4. Bringing it all together

#### FULL CODE SIMULATION DEMO AND COMPARISON RESULTS.

##### a) READING DATA AND UNIVARIATE IMPUTATION (PYTHON)

``` {python echo = TRUE, message = FALSE}

### READING AND REPLACING DATA WITH NA'S ##

# Reading in data frame.
original_df = read_true_values('data/train.csv')

# Simulated scenarios of removal data.
# [1] two continuous variables (cont0, cont1) with 10% removal
# [2] two categorical variables (cat0, cat1) with 10% removal
# [3] one continuous and one categorical (cont0, cat0) with 10% removal

# Column holding values.
column_one = ['cont0', 'cont1']
column_two = ['cat0', 'cat1']
column_three = ['cont0', 'cat0']

# Removing...
# YOU MUST USE .copy() SO IT IS NOT REFERENCE BASED!!!
nans_one = remove_random_values(original_df.copy(), column_one, 0.1 )
#nans_two = remove_random_values(original_df.copy(), column_two, 0.1 )
#nans_three = remove_random_values(original_df.copy(), column_three, 0.1 )

# UNIVARIATE IMPUTATION TECHNIQUE is in python so we apply now.
# Predicted values
simple_imputer_one = univariate_imputation_method(nans_one[column_one])
#simple_imputer_two = univariate_imputation_method(nans_two[column_two])
#simple_imputer_three = univariate_imputation_method(nans_three[column_three])

# COMPUTE UNIVARIATE PERFORMANCE METRICS
simple_imputer_one_results = performance_results_py(original_df, simple_imputer_one, nans_one, column_one)

# This is necessary due to bug in transformation of dataset from Python to R 
nans_one = nans_one.replace(np.nan, 'NA')
#nans_two = nans_two.replace(np.nan, 'NA')
#nans_three = nans_three.replace(np.nan, 'NA')

```

``` {r echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE}

# Need to bring original and random removal data in the R enviroment.

# Original Data.
original_df <- py$original_df

# Creating the column vectors being used.
column_one = c('cont0', 'cont1', 'cat0')
column_two = c('cat0', 'cat1', 'cont1')
column_three = c('cont0', 'cat0', 'cont3')

# NA data of the different simulation scenarios.
nans_one <- py$nans_one
#nans_two <- py$nans_two
#nans_three <- py$nans_three

# Wrangle Data in Appropriate Data.
nans_one <- wrangle_data_for_na(nans_one)
#nans_two <- wrangle_data_for_na(nans_two)
#nans_three <- wrangle_data_for_na(nans_three)

original_df <- wrangle_data_for_original(original_df)

```

``` {r echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE}

# Transferring Simple Imputer Results to R

simple_imputer_one_results <- py$simple_imputer_one_results
names(simple_imputer_one_results[[1]]) <- c("D", "PD", "mean", "sd")
names(simple_imputer_one_results[[2]]) <- c("D", "PD", "mean", "sd")
names(simple_imputer_one_results) <- c(py$column_one[1], py$column_one[2])

```

##### b) MICE IMPUTATION (R)

Imputing data using MICE.

``` {r echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE}

mice_imputer_one <- impute_using_mice(nans_one, column_one)
# mice_imputer_two <- impute_using_mice(nans_two, column_two)
# mice_imputer_three <- impute_using_mice(nans_three, column_three)

```

``` {r echo = FALSE, eval = TRUE}

# Need to remove non imputed columns. 
column_one = c('cont0', 'cont1')
column_two = c('cat0', 'cat1')
column_three = c('cont0', 'cat0')

```

Obtaining performance metrics for the MICE imputed data.

``` {r echo = TRUE, eval = TRUE}

mice_result_one <- performance_results_mice(original_df, mice_imputer_one, column_one)
# mice_result_two <- performance_results_mice(original_df, mice_imputer_two, column_two)
# mice_result_three <- performance_results_mice(original_df, mice_imputer_three, column_three)

```

##### c) MISSFOREST IMPUTATION (R)

``` {r echo = FALSE, eval = TRUE}

# Creating the column vectors being used.
column_one = c('cont0', 'cont1', 'cat0')
column_two = c('cat0', 'cat1', 'cont1')
column_three = c('cont0', 'cat0', 'cont3')

```

Imputing Data using missForest.

``` {r echo = TRUE, eval = TRUE}

missForest_imputer_one <- impute_using_missForest(nans_one, column_one)
# missForest_imputer_two <- impute_using_missForest(nans_two, column_two)
# missForest_imputer_three <- impute_using_missForest(nans_three, column_three)

```

``` {r echo = FALSE, eval = TRUE}

# Need to remove non imputed columns. 
column_one = c('cont0', 'cont1')
column_two = c('cat0', 'cat1')
column_three = c('cont0', 'cat0')

```

Obtaining performance metrics for the missforest imputed data.

``` {r echo = TRUE, eval = TRUE}

missForest_result_one <- performance_results_missForest(original_df, missForest_imputer_one, nans_one, column_one)
# missForest_result_two <- performance_results_missForest(original_df, missForest_imputer_two, nans_two, column_two)
# missForest_result_three <- performance_results_missForest(original_df, missForest_imputer_three, nans_three, column_three)

```

##### c) FINAL SCORES

The final scores of the mean difference between true and predicted, as well as their respective standard deviations are:

``` {r echo = FALSE, eval = TRUE, warning = FALSE}

# Compare results final.
print_metrics_obtained("One", column_one, simple_imputer_one_results, mice_result_one, missForest_result_one)

```


##### PLOTS

``` {r  eval = TRUE, echo = TRUE, warning = FALSE}
### FUNCTION
## Function to plot density plots to comparing numeric column imputations
## Input
# simulation: String holding the number of simulation and covariate exploring
# simple: List of all the D values for simple imputation
# micee: List of all D values for mice imputation
# forest: List of all D values for missForest imputations
plot_density <- function(simulation, Simple, Mice, MissForest) {
 
  # Must be <<data.frame>> not <<as.data.frame>> . Otherwise it does not create it correctly for some reason..
  plotingData <- data.frame(Simple,
                            Mice,
                            MissForest)
  
  # Convert data to fit densities
  # Imputation: column that will hold the old column names
  # Difference: column that will hold all the Differences computed for all imputers
  # Line under, columns we are gathering.
  densPlotting <- plotingData %>%
    gather(Imputation, Difference,
           Mice, MissForest, Simple)
  
  # Giving appropriate title for graph.
  title <- paste("Density Plot comparing techniques for Simulation", simulation)
  
  # Plotting the data using ggplot.
  ggplot(densPlotting, aes(Difference, fill = Imputation, colour = Imputation)) + 
    geom_density(alpha = 0.1) +
    xlab("Difference of True-Imputed value in Smilatuon") + 
    ylab("Density") + 
    ggtitle(title) 
}

# Calling the funciton to plot the data.
plot_density("One 'cont0'",
             c(simple_imputer_one_results$cont0$D),
             c(mice_result_one$D$cont0[[1]]),
             c(missForest_result_one$D$cont0))

```

``` {r  eval = TRUE, echo = TRUE, warning = FALSE}
### FUNCTION
## Function to plot error plots to comparing numeric column imputations
## Input
# simulation: String holding the number of simulation and covariate exploring
# means: List holding mean values for each imputation (simple, missForest, mice)
# sds: List holding sd values for each imputation (simple, missForest, mice)
# imputations: List holding the name imputations methods (simple, missForest, mice)
plot_error <- function(simulation, means, sds, imputations) {
  
  # Creating the data frame for the plot.
  error_data <- data.frame(means,
                           sds,
                           imputations)
  
  # Creating appropriate title for graph
  title <- paste("Comparing CI of mean difference produces for Simulation", simulation)
  
  # Plotting the data
  ggplot(error_data, aes(x = imputations, color = imputations)) +
  geom_errorbar(aes(ymax = means + 1.96*sds, ymin = means - 1.96*sds), position = "dodge") +
  xlab("Imputation Method") + 
  ylab("Mean +/- 1SD of the raw difference") +
  ggtitle(title)

  
}

# Calling function to plot error bars (compare mean's and sd's)
plot_error("One 'cont0'",
           c(simple_imputer_one_results$cont0$mean, missForest_result_one$mean$cont0, mice_result_one$mean$cont0[[1]]),
           c(simple_imputer_one_results$cont0$sd, missForest_result_one$sd$cont0, mice_result_one$sd$cont0[[1]]),
           c("Simple", "MissForest", "Mice"))

```


``` {r  eval = TRUE, echo = TRUE, warning = FALSE}
####################
# WILL BE INPUTTED IN FUNCTION
###################
### FUNCTION
## Function to plot density plots to comparing numeric column imputations
## Input
# simulation: String holding the number of simulation and covariate exploring
# simple: List of all the D values for simple imputation
# mice: List of all D values for mice imputation
# forest: List of all D values for missForest imputations
plot_density_with_CI <- function(simulation, Simple, Mice, MissForest) {
 
  # Must be <<data.frame>> not <<as.data.frame>> . Otherwise it does not create it correctly for some reason..
  plotingData <- data.frame(Simple,
                            Mice,
                            MissForest)
  
  # Convert data to fit densities
  # Imputation: column that will hold the old column names
  # Difference: column that will hold all the Differences computed for all imputers
  # Line under, columns we are gathering.
  densPlotting <- plotingData %>%
    gather(Imputation, Difference,
           Mice, MissForest, Simple)
  
  # Giving appropriate title for graph.
  title <- paste("Density Plot comparing techniques for Simulation", simulation)

  # Plotting the data using ggplot.
  ggplot(densPlotting, aes(Difference, fill = Imputation, colour = Imputation)) + 
    geom_density(alpha = 0.1) +
    geom_segment(aes(x=mean(Difference) + 1.96*sd(Difference), xend=mean(Difference) + 1.96*sd(Difference),
                     y=0, yend=3), alpha=0.5, lty="21") +
    geom_segment(aes(x=mean(Difference) - 1.96*sd(Difference), xend=mean(Difference) - 1.96*sd(Difference),
                     y=0, yend=3), alpha=0.5, lty="21") +
    #geom_text(aes(label = Imputation, y = 2)) +
    xlab("Difference of True-Imputed value in Smilatuon") + 
    ylab("Density") + 
    ggtitle(title) +
    facet_wrap(~Imputation)
}



# Calling the funciton to plot the data.
plot_density_with_CI("One 'cont0'",
             c(simple_imputer_one_results$cont0$D),
             c(mice_result_one$D$cont0[[1]]),
             c(missForest_result_one$D$cont0))


```

``` {r  eval = TRUE, echo = TRUE, warning = FALSE}
####################
# WILL BE INPUTTED IN FUNCTION
###################
### FUNCTION
## Function to plot density plots to comparing numeric column imputations
## Input
# simulation: String holding the number of simulation and covariate exploring
# simple: List of all the D values for simple imputation
# mice: List of all D values for mice imputation
# forest: List of all D values for missForest imputations
plot_density_histogram <- function(simulation, Simple, Mice, MissForest) {
 
  # Have to find lower and upper bounds for each metric.
  lower_simple <- mean(Simple) - 1.96 * sd(Simple)
  upper_simple <- mean(Simple) + 1.96 * sd(Simple)
  
  lower_mice <- mean(Mice) - 1.96 * sd(Mice)
  upper_mice <- mean(Mice) + 1.96 * sd(Mice)
  
  lower_forest <- mean(MissForest) - 1.96 * sd(MissForest)
  upper_forest <- mean(MissForest) + 1.96 * sd(MissForest)
  
  
  # Keeping Differences contained in the CI of each imputation.
  forest_CI <- MissForest[MissForest > lower_forest]
  forest_CI <- MissForest[MissForest < upper_forest]
  
  mice_CI <- Mice[Mice > lower_mice]
  mice_CI <- Mice[Mice < upper_mice]
  
  simple_CI <- Simple[Simple > lower_simple]
  simple_CI <- Simple[Simple < upper_simple]
  
  N_observ <- c(length(simple_CI),
                length(mice_CI),
                length(forest_CI))
  
  # Finding proportion that fall in CI
  percentage <- c(length(simple_CI) / length(Simple) * 100,
                length(mice_CI) / length(Mice) * 100,
                length(forest_CI) / length(MissForest) * 100)
  # Putting values in data frame to compare
  Imputation <- c("Simple", "Mice", "MissForest")
  compareData <- data.frame(N_observ,
                            Imputation)
  
  # Giving appropriate title for graph.
  title <- paste("Number of Observation obtained in 95% CI", simulation)
  
  
  # Plotting Data in Histogram
  ggplot(compareData, aes(x = Imputation, y = N_observ)) +
    geom_bar(stat = "identity", aes(fill = Imputation, colour = Imputation)) +
    geom_text(label = paste(round(percentage, digits=2), "%"),
              hjust = 1.5, size = 5, position = position_dodge(width = .75)) +
    coord_flip() + 
    xlab("Imputation Technique") + 
    ylab("Number of Observations in 95% CI") + 
    ggtitle(title) 
  
  
}



# Calling the funciton to plot the data.
plot_density_histogram("One 'cont0'",
             c(simple_imputer_one_results$cont0$D),
             c(mice_result_one$D$cont0[[1]]),
             c(missForest_result_one$D$cont0))


```






***






### Ignore for now

``` {python echo = FALSE, eval = FALSE}

def imputation_complete(complete_df, columns, percentage):
    """
    Function which brings together all the functions for a single step of the simulation study.
    These consists of:
    1. randomly dropping values from the dataset,
    2. fitting imputation methods, and
    3. evaluating the performance of the imputed data against the true data.

    :param df: pandas DataFrame which is the full data
    :param columns: list of columns to 'drop' values from. Note: must be string name of columns
    :param percentage: float input such as 0.20 (i.e. 20%)
    :return: results for each of the methods (currently only missforest and median imputer)
    """

    ##### COMPLETE CODE:

    ### 1. DROP VALUES RANDOMLY

    df_nans = remove_random_values(complete_df.copy(), columns, percentage)

    ### 2. COMPUTE METHODS

    median_imputed_data, missforest_imputed_data = univariate_imputation_methods(df_nans[columns])

    ### 3. EXTRACT TRUE VALUES AND COMPARE WITH IMPUTED VALUES

    results_median = []
    results_missforest = []
    for column in columns:

        # a. Extract boolean vector (True/False) to identify Imputed True Data Vectors
        boolean_values = (original_df != df_nans)[column].to_numpy().tolist()
        true_values = original_df[column][boolean_values]

        # c. Extract Imputed Data Vectors
        imputed_values_median = median_imputed_data[column][boolean_values].to_numpy().tolist()
        imputed_values_missforest = missforest_imputed_data[column][boolean_values].to_numpy().tolist()

        # d. Evaluate performance metrics
        results_median.append(performance_metrics(imputed_values_median, true_values))
        results_missforest.append(performance_metrics(imputed_values_missforest, true_values))

    return(results_median, results_missforest)


```